{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DIOMIRA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A nb to develop the cython version of DIOMIRA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: IPYTHONDIR=/Users/jjgomezcadenas/Documents/Development/IPYTHON\n"
     ]
    }
   ],
   "source": [
    "%env IPYTHONDIR=/Users/jjgomezcadenas/Documents/Development/IPYTHON"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%load_ext Cython"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import FEParam as FP\n",
    "import tables\n",
    "from time import time\n",
    "from Util import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classical fib function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def fib(n):\n",
    "    a,b = 0.0, 1.0\n",
    "    for i in range(n):\n",
    "        a,b = a+b,a\n",
    "    return a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%cython\n",
    "def cfib(int n):\n",
    "    cdef int i\n",
    "    cdef double a = 0.0, b= 1.0\n",
    "    for i in range(n):\n",
    "        a,b = a+b, a\n",
    "    return a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%timeit fib(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%timeit fib(90)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%timeit cfib(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%timeit cfib(90)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "f = 118./6050."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "1./f"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Rebin array"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Python version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def rebin_pmt_array(a,stride):\n",
    "    \"\"\"\n",
    "    rebins pmt array a according to stride\n",
    "    there is a rebin_array in util which uses\n",
    "    lenb = (len(a))/int(stride)\n",
    "    this version uses (lean(a)+1) to correct from the fact that the\n",
    "    MCRD is 599999 channels (should be 600000)\n",
    "    \"\"\"\n",
    "    \n",
    "    lenb = (len(a)+1)/int(stride)\n",
    "    b = np.zeros(lenb)\n",
    "    j=0\n",
    "    for i in range(lenb):\n",
    "        b[i] = np.sum(a[j:j+stride])\n",
    "        j+= stride\n",
    "    return b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cx = np.arange(0.,100., 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%time y = rebin_pmt_array(cx,10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%timeit y = rebin_pmt_array(cx,10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Cython version (pure compilation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%cython\n",
    "import numpy as np\n",
    "def rebin_pmt_array(a,stride):\n",
    "    \"\"\"\n",
    "    rebins pmt array a according to stride\n",
    "    there is a rebin_array in util which uses\n",
    "    lenb = (len(a))/int(stride)\n",
    "    this version uses (lean(a)+1) to correct from the fact that the\n",
    "    MCRD is 599999 channels (should be 600000)\n",
    "    \"\"\"\n",
    "    \n",
    "    lenb = (len(a)+1)/int(stride)\n",
    "    b = np.zeros(lenb)\n",
    "    j=0\n",
    "    for i in range(lenb):\n",
    "        b[i] = np.sum(a[j:j+stride])\n",
    "        j+= stride\n",
    "    return b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%timeit rebin_pmt_array(cx,10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### cython version, declares variables but still uses np.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%cython\n",
    "import numpy as np\n",
    "cimport numpy as np\n",
    "def crebin_pmt_array(double [:] a,int stride):\n",
    "    \"\"\"\n",
    "    rebins pmt array a according to stride\n",
    "    there is a rebin_array in util which uses\n",
    "    lenb = (len(a))/int(stride)\n",
    "    this version uses (lean(a)+1) to correct from the fact that the\n",
    "    MCRD is 599999 channels (should be 600000)\n",
    "    \"\"\"\n",
    "    \n",
    "    cdef:\n",
    "        int lenb, i, j\n",
    "        double [:] b\n",
    "    \n",
    "    lena =   a.shape[0]   \n",
    "    lenb = a.shape[0]/stride\n",
    "    \n",
    "    b = np.zeros(lenb, dtype=np.double)\n",
    "    \n",
    "    j=0\n",
    "    \n",
    "    for i in range(lenb):\n",
    "        b[i] = np.sum(a[j:j+stride])\n",
    "        j+= stride\n",
    "    \n",
    "    \n",
    "    return np.asarray(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%timeit z = crebin_pmt_array(cx,10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*NB: the code runs 3 times SLOWER than the cython version*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### cythonizes the sum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%cython\n",
    "import numpy as np\n",
    "cimport numpy as np\n",
    "def c2rebin_pmt_array(double [:] a,int stride):\n",
    "    \"\"\"\n",
    "    rebins pmt array a according to stride\n",
    "    there is a rebin_array in util which uses\n",
    "    lenb = (len(a))/int(stride)\n",
    "    this version uses (lean(a)+1) to correct from the fact that the\n",
    "    MCRD is 599999 channels (should be 600000)\n",
    "    \"\"\"\n",
    "    \n",
    "    cdef:\n",
    "        int lenb, i, j,k\n",
    "        double [:] b\n",
    "        double part_sum\n",
    "    \n",
    "    lena =   a.shape[0]   \n",
    "    lenb = a.shape[0]/stride\n",
    "    \n",
    "    b = np.zeros(lenb)\n",
    "    \n",
    "    j=0\n",
    "    \n",
    "    for i in range(lenb):\n",
    "        part_sum = 0.\n",
    "        for k in range(j, j + stride): \n",
    "            part_sum += a[k] \n",
    "        b[i] = part_sum\n",
    "        j+= stride\n",
    "    \n",
    "    return np.asarray(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%timeit z = c2rebin_pmt_array(cx,10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*IMPROVEMENT*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Direct use of nd.array() in function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%cython\n",
    "import numpy as np\n",
    "cimport numpy as np\n",
    "def c3rebin_pmt_array(double [:] a,int stride):\n",
    "    \"\"\"\n",
    "    rebins pmt array a according to stride\n",
    "    there is a rebin_array in util which uses\n",
    "    lenb = (len(a))/int(stride)\n",
    "    this version uses (lean(a)+1) to correct from the fact that the\n",
    "    MCRD is 599999 channels (should be 600000)\n",
    "    \"\"\"\n",
    "    \n",
    "    cdef:\n",
    "        int lenb, i, j,k\n",
    "        double part_sum\n",
    "      \n",
    "    lenb = a.shape[0]/stride\n",
    "    cdef np.ndarray[np.float64_t, ndim=1] b = np.zeros(lenb) \n",
    "    \n",
    "    j=0\n",
    "    for i in range(lenb):\n",
    "        part_sum = 0.\n",
    "        for k in range(j, j + stride): \n",
    "            part_sum += a[k] \n",
    "        b[i] = part_sum\n",
    "        j+= stride\n",
    "    \n",
    "    return b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%timeit z = c3rebin_pmt_array(cx,10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Further improvement!*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### switch off checks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%cython\n",
    "import numpy as np\n",
    "cimport numpy as np\n",
    "from cython cimport boundscheck, wraparound\n",
    "def c4rebin_pmt_array(np.ndarray[np.float64_t, ndim=1] a,int stride):\n",
    "    \"\"\"\n",
    "    rebins pmt array a according to stride\n",
    "    there is a rebin_array in util which uses\n",
    "    lenb = (len(a))/int(stride)\n",
    "    this version uses (lean(a)+1) to correct from the fact that the\n",
    "    MCRD is 599999 channels (should be 600000)\n",
    "    \"\"\"\n",
    "    \n",
    "    cdef:\n",
    "        int lenb, i, j,k\n",
    "        double part_sum\n",
    "      \n",
    "    lenb = a.shape[0]/stride\n",
    "    cdef np.ndarray[np.float64_t, ndim=1] b = np.zeros(lenb) \n",
    "    \n",
    "    j=0\n",
    "    with boundscheck(False), wraparound(False):\n",
    "        for i in range(lenb):\n",
    "            part_sum = 0.\n",
    "            for k in range(j, j + stride): \n",
    "                part_sum += a[k] \n",
    "                b[i] = part_sum\n",
    "            j+= stride\n",
    "    \n",
    "    return b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%timeit z = c4rebin_pmt_array(cx,10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%timeit z = c4rebin_pmt_array(cx,10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%timeit z = rebin_pmt_array(cx,10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*About a factor 15 improvement*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Profiling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import cProfile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def main():\n",
    "    cx = np.arange(0.,1000000., 1)\n",
    "    z = rebin_pmt_array(cx,10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cProfile.run('main()', sort='time')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def cmain():\n",
    "    cx = np.arange(0.,1000000., 1)\n",
    "    z = c4rebin_pmt_array(cx,10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cProfile.run('cmain()', sort='time')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*NB It seems that the improvement for large arrays can be much larger***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DIOMIRA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "DIOMIRA\n",
    "JJGC August 2016\n",
    "\n",
    "What DIOMIRA does:\n",
    "1) Reads a MCRD file containing MC waveforms for the 12 PMTs of the EP.\n",
    "   Each waveform contains number of PEs in bins of 1 ns.\n",
    "2) Convolves the PE waveform with the response of the FEE electronics.\n",
    "3) Decimates the waveform, simulating the effect of the DAQ sampling (25 ns bins)\n",
    "4) Writes a RWF file with the new data and adds the FEE simulation parameters as metadata\n",
    "\"\"\"\n",
    "\n",
    "from __future__ import print_function\n",
    "from Util import *\n",
    "from LogConfig import *\n",
    "from Configure import configure\n",
    "from Nh5 import *\n",
    "from cities import diomira\n",
    "from SensorsResponse import *\n",
    "\n",
    "import tables\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "ChangeLog:\n",
    "\n",
    "26.9 \n",
    "\n",
    "Changed types of PMTRWF, SIPMRWF and PMTTWF to Float32 for \n",
    "    (compatibility with ART/GATE)\n",
    "\n",
    "Do not store EPMT and ESIPM (can be computed on the fly)\n",
    "\n",
    "Change sign of pmtrwf to negative (as produced by the DAQ)\n",
    "\"\"\"\n",
    "\n",
    "def DIOMIRA(argv):\n",
    "    DEBUG_LEVEL, INFO, CFP = configure(argv[0],argv[1:])\n",
    "   \n",
    "    if INFO:\n",
    "        print(diomira)\n",
    "\n",
    "    #wait()\n",
    "    \n",
    "    print(\"\"\"\n",
    "        DIOMIRA:\n",
    "         1. Reads an MCRD file produced by art/centella, which stores MCRD \n",
    "         waveforms for PMTs (bins of 1 ns)\n",
    "        and the SiPMs (bins of 1 mus)\n",
    "            \n",
    "\n",
    "        2. Simulates the response of the energy plane in the PMTs MCRD, \n",
    "        and produces both RWF and TWF:\n",
    "        see: http://localhost:8931/notebooks/Nh5-Event-Model.ipynb#Reconstructed-Objects\n",
    "        \n",
    "            \n",
    "        3. Simulates the response of the tracking plane in the SiPMs MCRD and outputs\n",
    "            SiPM RWF (not yet implemented, for the time being simply copy the MCRD)\n",
    "\n",
    "        4. Add a table describing the FEE parameters used for simulation\n",
    "\n",
    "        5. Copies the tables on geometry, detector data and MC\n",
    "\n",
    "\n",
    "        \"\"\")\n",
    "    FP.print_FEE()\n",
    "    #wait()\n",
    "\n",
    "    PATH_IN =CFP['PATH_IN']\n",
    "    PATH_OUT =CFP['PATH_OUT']\n",
    "    FILE_IN =CFP['FILE_IN']\n",
    "    FILE_OUT =CFP['FILE_OUT']\n",
    "    FIRST_EVT =CFP['FIRST_EVT']\n",
    "    LAST_EVT =CFP['LAST_EVT']\n",
    "    RUN_ALL =CFP['RUN_ALL']\n",
    "    CLIB =CFP['CLIB']\n",
    "    CLEVEL =CFP['CLEVEL']\n",
    "    NEVENTS = LAST_EVT - FIRST_EVT\n",
    "\n",
    "    print('Debug level = {}'.format(DEBUG_LEVEL))\n",
    "\n",
    "    logger.info(\"input path ={}; output path = {}; file_in ={} file_out ={}\".format(\n",
    "        PATH_IN,PATH_OUT,FILE_IN, FILE_OUT))\n",
    "\n",
    "    logger.info(\"first event = {} last event = {} nof events requested = {} \".format(\n",
    "        FIRST_EVT,LAST_EVT,NEVENTS))\n",
    "\n",
    "    logger.info(\"Compression library = {} Compression level = {} \".format(\n",
    "        CLIB,CLEVEL))\n",
    "\n",
    "    # open the input file \n",
    "    with tables.open_file(\"{}/{}\".format(PATH_IN,FILE_IN), \"r+\") as h5in: \n",
    "        # access the PMT raw data in file \n",
    "\n",
    "        pmtrd_ = h5in.root.pmtrd\n",
    "        sipmrd_ = h5in.root.sipmrd\n",
    "\n",
    "        #pmtrd_.shape = (nof_events, nof_sensors, wf_length)\n",
    "        NPMT = pmtrd_.shape[1]\n",
    "        NSIPM = sipmrd_.shape[1]\n",
    "        PMTWL = pmtrd_.shape[2] \n",
    "        PMTWL_FEE = int((PMTWL+1)/FP.time_DAQ)\n",
    "        SIPMWL = sipmrd_.shape[2]\n",
    "        NEVENTS_DST = pmtrd_.shape[0]\n",
    "\n",
    "        logger.info(\"nof PMTs = {} nof  SiPMs = {} nof events in input DST = {} \".format(\n",
    "        NPMT,NSIPM,NEVENTS_DST))\n",
    "\n",
    "        logger.info(\"lof SiPM WF = {} lof PMT WF (MC) = {} lof PMT WF (FEE) = {}\".format(\n",
    "        PMTWL,SIPMWL,PMTWL_FEE))\n",
    "\n",
    "        #wait()\n",
    "\n",
    "        #access the geometry and the sensors metadata info\n",
    "\n",
    "        geom_t = h5in.root.Detector.DetectorGeometry\n",
    "        pmt_t = h5in.root.Sensors.DataPMT\n",
    "        sipm_t = h5in.root.Sensors.DataSiPM\n",
    "        mctrk_t = h5in.root.MC.MCTracks\n",
    "\n",
    "        \n",
    "        # open the output file \n",
    "        with tables.open_file(\"{}/{}\".format(PATH_OUT,FILE_OUT), \"w\",\n",
    "            filters=tables.Filters(complib=CLIB, complevel=CLEVEL)) as h5out:\n",
    " \n",
    "            # create a group to store MC data\n",
    "            mcgroup = h5out.create_group(h5out.root, \"MC\")\n",
    "            # copy the mctrk table\n",
    "            mctrk_t.copy(newparent=mcgroup)\n",
    "\n",
    "            # create a group  to store geom data\n",
    "            detgroup = h5out.create_group(h5out.root, \"Detector\")\n",
    "            # copy the geom table\n",
    "            geom_t.copy(newparent=detgroup)\n",
    "\n",
    "            # create a group  store sensor data\n",
    "            sgroup = h5out.create_group(h5out.root, \"Sensors\")\n",
    "            # copy the pmt table\n",
    "            pmt_t.copy(newparent=sgroup)\n",
    "            # copy the sipm table\n",
    "            sipm_t.copy(newparent=sgroup)\n",
    "\n",
    "            # create a table to store Energy plane FEE data and hang it from MC group\n",
    "            fee_table = h5out.create_table(mcgroup, \"FEE\", FEE,\n",
    "                          \"EP-FEE parameters\",\n",
    "                           tables.Filters(0))\n",
    "\n",
    "            # fill table\n",
    "            FEE_param_table(fee_table)\n",
    "\n",
    "            # create a group to store RawData\n",
    "            rgroup = h5out.create_group(h5out.root, \"RD\")\n",
    "            \n",
    "            # create an extensible array to store the RWF waveforms\n",
    "            pmtrwf = h5out.create_earray(h5out.root.RD, \"pmtrwf\", \n",
    "                                    atom=tables.Float32Atom(), \n",
    "                                    shape=(0, NPMT, PMTWL_FEE), \n",
    "                                    expectedrows=NEVENTS_DST)\n",
    "            \n",
    "            # create an extensible array to store the TWF waveforms\n",
    "            pmttwf = h5out.create_earray(h5out.root.RD, \"pmttwf\", \n",
    "                                    atom=tables.Float32Atom(), \n",
    "                                    shape=(0, NPMT, PMTWL_FEE), \n",
    "                                    expectedrows=NEVENTS_DST)\n",
    "            \n",
    "\n",
    "            sipmrwf = h5out.create_earray(h5out.root.RD, \"sipmrwf\", \n",
    "                                    atom=tables.Float32Atom(), \n",
    "                                    shape=(0, NSIPM, SIPMWL), \n",
    "                                    expectedrows=NEVENTS_DST)\n",
    "\n",
    "            # #create an extensible array to store the energy in PES of PMTs \n",
    "            # epmt = h5out.create_earray(h5out.root.RD, \"epmt\", \n",
    "            #                         atom=tables.FloatAtom(), \n",
    "            #                         shape=(0, NPMT), \n",
    "            #                         expectedrows=NEVENTS_DST)\n",
    "\n",
    "            # # create an extensible array to store the energy in PES of SiPMs \n",
    "            # esipm = h5out.create_earray(h5out.root.RD, \"esipm\", \n",
    "            #                         atom=tables.FloatAtom(), \n",
    "            #                         shape=(0, NSIPM), \n",
    "            #                         expectedrows=NEVENTS_DST)\n",
    "\n",
    "            \n",
    "            if NEVENTS > NEVENTS_DST and RUN_ALL == False:\n",
    "                print(\"\"\"\n",
    "                Refusing to run: you have requested\n",
    "                FIRST_EVT = {}\n",
    "                LAST_EVT  = {}\n",
    "                Thus you want to run over {} events\n",
    "                but the size of the DST is {} events.\n",
    "                Please change your choice or select RUN_ALL = TRUE\n",
    "                to run over the whole DST when this happens\n",
    "                \"\"\".format(FIRST_EVT,LAST_EVT,NEVENTS,NEVENTS_DST))\n",
    "                sys.exit(0)\n",
    "            elif  NEVENTS > NEVENTS_DST and RUN_ALL == True:\n",
    "                FIRST_EVT = 0\n",
    "                LAST_EVT = NEVENTS_DST\n",
    "                NEVENTS = NEVENTS_DST\n",
    "\n",
    "\n",
    "            for i in range(FIRST_EVT,LAST_EVT):\n",
    "                logger.info(\"-->event number ={}\".format(i))\n",
    "\n",
    "                #simulate PMT response and return an array with RWF\n",
    "                dataPMT = simulate_pmt_response(i,pmtrd_)\n",
    "\n",
    "                #convert to float\n",
    "                dataPMT.astype(float) \n",
    "                #TWF\n",
    "                 \n",
    "                truePMT = rebin_signal(i,pmtrd_, int(FP.time_DAQ))\n",
    "                truePMT.astype(float)\n",
    "                \n",
    "                logger.info(\"truePMT shape ={}\".format(truePMT.shape))\n",
    "                logger.info(\"dataPMT shape ={}\".format(dataPMT.shape))\n",
    "                \n",
    "                #RWF for pmts\n",
    "                pmtrwf.append(dataPMT.reshape(1, NPMT, PMTWL_FEE))\n",
    "                #pmtrd.append(dataPMT.reshape(1, NPMT, PMTWL))\n",
    "                \n",
    "                #TWF for pmts\n",
    "                pmttwf.append(truePMT.reshape(1, NPMT, PMTWL_FEE))\n",
    "                #pmtrd.append(dataPMT.reshape(1, NPMT, PMTWL))\n",
    "                   \n",
    "                #simulate SiPM response and return an array with new WF\n",
    "                dataSiPM = simulate_sipm_response(i,sipmrd_)\n",
    "                dataSiPM.astype(float)\n",
    "                \n",
    "                #append to SiPM EARRAY\n",
    "                sipmrwf.append(dataSiPM.reshape(1, NSIPM, SIPMWL))\n",
    "\n",
    "                # #fill ene_pmt vector\n",
    "                # enePMT = energy_pes(i, pmtrd_)\n",
    "                # #append to epmt EARRAY\n",
    "                # epmt.append(enePMT.reshape(1, NPMT))\n",
    "\n",
    "                # #fill ene_sipm vector\n",
    "                # eneSIPM = energy_pes(i, sipmrd_)\n",
    "                # esipm.append(eneSIPM.reshape(1, NSIPM))\n",
    "\n",
    "            pmtrwf.flush()\n",
    "            pmttwf.flush()\n",
    "            sipmrwf.flush()\n",
    "            #epmt.flush()\n",
    "            #esipm.flush()\n",
    "\n",
    "\n",
    "    print(\"Leaving Diomira. Safe travels!\")\n",
    "\n",
    "\n",
    "\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%less ../../Config/DIOMIRA_NA_ZLIB_test2.csv"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# Configuration file for DIOMIRA\n",
    "# The parameters for DIOMIRA are:\n",
    "#\n",
    "#        PATH_IN = path to input DST file (must be a MCRD file)\n",
    "#        FILE_IN = name of input DST file\n",
    "#        PATH_OUT = path to output DST file (RWF file)\n",
    "#        FILE_OUT = name of ouput DST file (RWF file)\n",
    "#        FIRST_EVT,LAST_EVT,RUN_ALL,\n",
    "#\n",
    "#        RUN_ALL is used to decide whether to run all the events in the file\n",
    "#        in case that the total number of events requested (LAST_EVT-FIRST_EVT) \n",
    "#        exceeds the number of events in the DST file. If RUN_ALL is set to 1 (True), \n",
    "#        the script will run over all elements in the DST, \n",
    "#        otherwise it will exit with a warning.\n",
    "#        CLIB = compression library used: values can be 'ZLIB', 'BLOSC' or 'NONE'\n",
    "#        CLEVEL = compression level\n",
    "#\n",
    "PATH_IN,PATH_OUT,FILE_IN,FILE_OUT,FIRST_EVT,LAST_EVT,RUN_ALL,CLIB,CLEVEL, END \n",
    "/Users/jjgomezcadenas/Documents/Development/NEXT/data/Waveforms/WF-NA-ZLIB/,/Users/jjgomezcadenas/Documents/Development/NEXT/data/Waveforms/25ns/,WF_Na_1Kevts_comp1_chunk32k.h5,WF_Na_ZLIB_test10_RWF.h5,0,10,1,zlib,1,1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Profile DIOMIRA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cProfile.run(\"DIOMIRA(['DIOMIRA','-i','-d','INFO','-c','../../Config/DIOMIRA_NA_ZLIB_test2.csv'])\", sort='time')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Profiling shows that rebin_array is one of the main issues. Start cythonizing it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%cython\n",
    "from __future__ import print_function\n",
    "from Util import *\n",
    "from LogConfig import *\n",
    "import FEParam as FP\n",
    "import SPE as SP\n",
    "import FEE2 as FE\n",
    "\n",
    "#import tables\n",
    "from FEE2 import down_scale_signal_\n",
    "\n",
    "import numpy as np\n",
    "cimport numpy as np\n",
    "from cython cimport boundscheck, wraparound\n",
    "\n",
    "def rebin_pmt_array(np.ndarray[np.int32_t, ndim=1] a,int stride):\n",
    "    \"\"\"\n",
    "    rebins pmt array a according to stride\n",
    "    there is a rebin_array in util which uses\n",
    "    lenb = (len(a))/int(stride)\n",
    "    this version uses (lean(a)+1) to correct from the fact that the\n",
    "    MCRD is 599999 channels (should be 600000)\n",
    "    \"\"\"\n",
    "    \n",
    "    logger.info(\"-->*cython::rebin_pmt_array\")\n",
    "    cdef:\n",
    "        int lenb, i, j,k\n",
    "        int part_sum\n",
    "      \n",
    "    lenb = (a.shape[0]+1)/stride\n",
    "    cdef np.ndarray[np.int32_t, ndim=1] b = np.zeros(lenb) \n",
    "    \n",
    "    j=0\n",
    "    with boundscheck(False), wraparound(False):\n",
    "        for i in range(lenb):\n",
    "            part_sum = 0\n",
    "            for k in range(j, j + stride): \n",
    "                part_sum += a[k] \n",
    "                b[i] = part_sum\n",
    "            j+= stride\n",
    "    \n",
    "    return b\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "Code\n",
    "\"\"\"\n",
    "\n",
    "def FEE_param_table(fee_table):\n",
    "    \"\"\"\n",
    "    Stores the parameters of the EP FEE simulation \n",
    "    \"\"\"\n",
    "    \n",
    "    print(\"calling the cython version\")\n",
    "    \n",
    "    row = fee_table.row\n",
    "    row['offset'] = FP.offset\n",
    "    row['pmt_gain'] = FP.PMT_GAIN\n",
    "    row['V_gain'] = FP.V_GAIN\n",
    "    row['R'] = FP.R\n",
    "    row['C12'] = FP.C12\n",
    "    row['CO12'] = FP.C12 # to be rewritten by ISIDORA\n",
    "    row['time_step'] = FP.time_step\n",
    "    row['time_daq'] = FP.time_DAQ\n",
    "    row['freq_LPF'] = FP.freq_LPF\n",
    "    row['freq_HPF'] = 1./(2*pi*FP.R*FP.C)\n",
    "    row['LSB'] = FP.LSB\n",
    "    row['volts_to_adc'] = FP.voltsToAdc/volt\n",
    "    row['noise_fee_rms'] = FP.NOISE_FEE\n",
    "    row['noise_adc'] = FP.NOISE_ADC\n",
    "    \n",
    "    row.append()\n",
    "    \n",
    "\n",
    "def energy_pes(event_number, sensord):\n",
    "    \"\"\"\n",
    "    Sum the WFs of PMTs and SiPMs (MC) and store the total energy in PES\n",
    "    \"\"\"     \n",
    "    rdata = []\n",
    "\n",
    "    for j in range(sensord.shape[1]):\n",
    "        swf = sensord[event_number, j]\n",
    "        ene = np.sum(swf)\n",
    "        rdata.append(ene)\n",
    "        \n",
    "    return np.array(rdata) \n",
    "\n",
    "def simulate_sipm_response(event_number,sipmrd_):\n",
    "    \"\"\"\n",
    "    For the moment use a dummy rutne that simply copies the sipm EARRAY\n",
    "    \"\"\"\n",
    "    rdata = []\n",
    "\n",
    "    for j in range(sipmrd_.shape[1]):\n",
    "        rdata.append(sipmrd_[event_number, j])\n",
    "    return np.array(rdata)\n",
    "\n",
    "\n",
    "def simulate_pmt_response(event_number,pmtrd_):\n",
    "    \"\"\"\n",
    "    Sensor Response\n",
    "    Given a signal in PE (photoelectrons in bins of 1 ns) and the response function of \n",
    "    for a single photoelectron (spe) and front-end electronics (fee)\n",
    "    this function produces the PMT raw data (adc counts bins 25 ns)\n",
    "\n",
    "    pmtrd_ dataset that holds the PMT PE data for each PMT\n",
    "    pmtrd25 dataset to be created with adc counts, bins 25 ns \n",
    "    after convoluting with electronics\n",
    "    \"\"\"\n",
    "    \n",
    "    logger.info(\"-->*cython::simulate_pmt_response, event ={}\".format(event_number))\n",
    "  \n",
    "    rdata = []\n",
    "\n",
    "    for j in range(pmtrd_.shape[1]):\n",
    "        logger.info(\"-->PMT number ={}\".format(j))\n",
    "                \n",
    "        pmt = pmtrd_[event_number, j] #waveform for event event_number, PMT j\n",
    "        \n",
    "        fee = FE.FEE(C=FP.C12[j],R= FP.R, f=FP.freq_LPF, RG=FP.V_GAIN) \n",
    "        spe = SP.SPE(pmt_gain=FP.PMT_GAIN,x_slope = 5*ns,x_flat = 1*ns)\n",
    "    \n",
    "        signal_PMT = spe.SpePulseFromVectorPE(pmt) #PMT response\n",
    "\n",
    "        #Front end response to PMT pulse (in volts)\n",
    "        signal_fee = fee.FEESignal(signal_PMT, noise_rms=FP.NOISE_FEE) \n",
    "\n",
    "        #Signal out of DAQ\n",
    "        #positive signal convention\n",
    "        #signal_daq = fee.daqSignal(signal_fee, noise_rms=0) - FP.offset\n",
    "        #negative signals convention!\n",
    "\n",
    "        signal_daq = FP.offset -fee.daqSignal(signal_fee, noise_rms=0) \n",
    "    \n",
    "        rdata.append(signal_daq)\n",
    "    return np.array(rdata)\n",
    "\n",
    "def decimate_signal(event_number,pmtrd_):\n",
    "    \"\"\"\n",
    "    Decimates the MCRD signal to produce TWF (pes, bins 25 ns)\n",
    "    \"\"\"\n",
    "  \n",
    "    rdata = []\n",
    "\n",
    "    for j in range(pmtrd_.shape[1]):\n",
    "        logger.debug(\"-->PMT number ={}\".format(j))\n",
    "                \n",
    "        pmt = pmtrd_[event_number, j] #waveform for event event_number, PMT j\n",
    "        twf = down_scale_signal_(pmt, int(FP.time_DAQ))\n",
    "        \n",
    "        \n",
    "        rdata.append(twf)\n",
    "    return np.array(rdata)\n",
    "\n",
    "# def rebin_pmt_array(a,stride):\n",
    "#     \"\"\"\n",
    "#     rebins pmt array a according to stride\n",
    "#     there is a rebin_array in util which uses\n",
    "#     lenb = (len(a))/int(stride)\n",
    "#     this version uses (lean(a)+1) to correct from the fact that the\n",
    "#     MCRD is 599999 channels (should be 600000)\n",
    "#     \"\"\"\n",
    "    \n",
    "#     lenb = (len(a)+1)/int(stride)\n",
    "#     b = np.zeros(lenb)\n",
    "#     j=0\n",
    "#     for i in range(lenb):\n",
    "#         b[i] = np.sum(a[j:j+stride])\n",
    "#         j+= stride\n",
    "#     return b\n",
    "\n",
    "def rebin_signal(event_number,pmtrd_, stride):\n",
    "    \"\"\"\n",
    "    rebins the MCRD signal to produce TWF (pes, bins 25 ns)\n",
    "    \"\"\"\n",
    "    \n",
    "    rdata = []\n",
    "    logger.info(\"-->*cython::rebin_signal, event ={}\".format(event_number))\n",
    "\n",
    "    for j in range(pmtrd_.shape[1]):\n",
    "        logger.info(\"-->PMT number ={}\".format(j))\n",
    "                \n",
    "        pmt = pmtrd_[event_number, j] #waveform for event event_number, PMT j\n",
    "        twf = rebin_pmt_array(pmt, stride)\n",
    "        \n",
    "        rdata.append(twf)\n",
    "    return np.array(rdata)\n",
    "\n",
    "  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function _cython_magic_82a0b0ceee12bcc9415fcb00039019cf.rebin_signal>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rebin_signal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "DIOMIRA\n",
    "JJGC August 2016\n",
    "\n",
    "What DIOMIRA does:\n",
    "1) Reads a MCRD file containing MC waveforms for the 12 PMTs of the EP.\n",
    "   Each waveform contains number of PEs in bins of 1 ns.\n",
    "2) Convolves the PE waveform with the response of the FEE electronics.\n",
    "3) Decimates the waveform, simulating the effect of the DAQ sampling (25 ns bins)\n",
    "4) Writes a RWF file with the new data and adds the FEE simulation parameters as metadata\n",
    "\"\"\"\n",
    "\n",
    "from __future__ import print_function\n",
    "from Util import *\n",
    "from LogConfig import *\n",
    "from Configure import configure\n",
    "from Nh5 import *\n",
    "from cities import diomira\n",
    "#from SensorsResponse import *\n",
    "\n",
    "import tables\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "ChangeLog:\n",
    "\n",
    "26.9 \n",
    "\n",
    "Changed types of PMTRWF, SIPMRWF and PMTTWF to Float32 for \n",
    "    (compatibility with ART/GATE)\n",
    "\n",
    "Do not store EPMT and ESIPM (can be computed on the fly)\n",
    "\n",
    "Change sign of pmtrwf to negative (as produced by the DAQ)\n",
    "\"\"\"\n",
    "\n",
    "def DIOMIRA(argv):\n",
    "    DEBUG_LEVEL, INFO, CFP = configure(argv[0],argv[1:])\n",
    "   \n",
    "    if INFO:\n",
    "        print(diomira)\n",
    "\n",
    "    #wait()\n",
    "    \n",
    "    print(\"\"\"\n",
    "        DIOMIRA:\n",
    "         1. Reads an MCRD file produced by art/centella, which stores MCRD \n",
    "         waveforms for PMTs (bins of 1 ns)\n",
    "        and the SiPMs (bins of 1 mus)\n",
    "            \n",
    "\n",
    "        2. Simulates the response of the energy plane in the PMTs MCRD, \n",
    "        and produces both RWF and TWF:\n",
    "        see: http://localhost:8931/notebooks/Nh5-Event-Model.ipynb#Reconstructed-Objects\n",
    "        \n",
    "            \n",
    "        3. Simulates the response of the tracking plane in the SiPMs MCRD and outputs\n",
    "            SiPM RWF (not yet implemented, for the time being simply copy the MCRD)\n",
    "\n",
    "        4. Add a table describing the FEE parameters used for simulation\n",
    "\n",
    "        5. Copies the tables on geometry, detector data and MC\n",
    "\n",
    "\n",
    "        \"\"\")\n",
    "    FP.print_FEE()\n",
    "    #wait()\n",
    "\n",
    "    PATH_IN =CFP['PATH_IN']\n",
    "    PATH_OUT =CFP['PATH_OUT']\n",
    "    FILE_IN =CFP['FILE_IN']\n",
    "    FILE_OUT =CFP['FILE_OUT']\n",
    "    FIRST_EVT =CFP['FIRST_EVT']\n",
    "    LAST_EVT =CFP['LAST_EVT']\n",
    "    RUN_ALL =CFP['RUN_ALL']\n",
    "    CLIB =CFP['CLIB']\n",
    "    CLEVEL =CFP['CLEVEL']\n",
    "    NEVENTS = LAST_EVT - FIRST_EVT\n",
    "\n",
    "    print('Debug level = {}'.format(DEBUG_LEVEL))\n",
    "\n",
    "    logger.info(\"input path ={}; output path = {}; file_in ={} file_out ={}\".format(\n",
    "        PATH_IN,PATH_OUT,FILE_IN, FILE_OUT))\n",
    "\n",
    "    logger.info(\"first event = {} last event = {} nof events requested = {} \".format(\n",
    "        FIRST_EVT,LAST_EVT,NEVENTS))\n",
    "\n",
    "    logger.info(\"Compression library = {} Compression level = {} \".format(\n",
    "        CLIB,CLEVEL))\n",
    "\n",
    "    # open the input file \n",
    "    with tables.open_file(\"{}/{}\".format(PATH_IN,FILE_IN), \"r+\") as h5in: \n",
    "        # access the PMT raw data in file \n",
    "\n",
    "        pmtrd_ = h5in.root.pmtrd\n",
    "        sipmrd_ = h5in.root.sipmrd\n",
    "\n",
    "        #pmtrd_.shape = (nof_events, nof_sensors, wf_length)\n",
    "        NPMT = pmtrd_.shape[1]\n",
    "        NSIPM = sipmrd_.shape[1]\n",
    "        PMTWL = pmtrd_.shape[2] \n",
    "        PMTWL_FEE = int((PMTWL+1)/FP.time_DAQ)\n",
    "        SIPMWL = sipmrd_.shape[2]\n",
    "        NEVENTS_DST = pmtrd_.shape[0]\n",
    "\n",
    "        logger.info(\"nof PMTs = {} nof  SiPMs = {} nof events in input DST = {} \".format(\n",
    "        NPMT,NSIPM,NEVENTS_DST))\n",
    "\n",
    "        logger.info(\"lof SiPM WF = {} lof PMT WF (MC) = {} lof PMT WF (FEE) = {}\".format(\n",
    "        PMTWL,SIPMWL,PMTWL_FEE))\n",
    "\n",
    "        #wait()\n",
    "\n",
    "        #access the geometry and the sensors metadata info\n",
    "\n",
    "        geom_t = h5in.root.Detector.DetectorGeometry\n",
    "        pmt_t = h5in.root.Sensors.DataPMT\n",
    "        sipm_t = h5in.root.Sensors.DataSiPM\n",
    "        mctrk_t = h5in.root.MC.MCTracks\n",
    "\n",
    "        \n",
    "        # open the output file \n",
    "        with tables.open_file(\"{}/{}\".format(PATH_OUT,FILE_OUT), \"w\",\n",
    "            filters=tables.Filters(complib=CLIB, complevel=CLEVEL)) as h5out:\n",
    " \n",
    "            # create a group to store MC data\n",
    "            mcgroup = h5out.create_group(h5out.root, \"MC\")\n",
    "            # copy the mctrk table\n",
    "            mctrk_t.copy(newparent=mcgroup)\n",
    "\n",
    "            # create a group  to store geom data\n",
    "            detgroup = h5out.create_group(h5out.root, \"Detector\")\n",
    "            # copy the geom table\n",
    "            geom_t.copy(newparent=detgroup)\n",
    "\n",
    "            # create a group  store sensor data\n",
    "            sgroup = h5out.create_group(h5out.root, \"Sensors\")\n",
    "            # copy the pmt table\n",
    "            pmt_t.copy(newparent=sgroup)\n",
    "            # copy the sipm table\n",
    "            sipm_t.copy(newparent=sgroup)\n",
    "\n",
    "            # create a table to store Energy plane FEE data and hang it from MC group\n",
    "            fee_table = h5out.create_table(mcgroup, \"FEE\", FEE,\n",
    "                          \"EP-FEE parameters\",\n",
    "                           tables.Filters(0))\n",
    "\n",
    "            # fill table\n",
    "            FEE_param_table(fee_table)\n",
    "\n",
    "            # create a group to store RawData\n",
    "            rgroup = h5out.create_group(h5out.root, \"RD\")\n",
    "            \n",
    "            # create an extensible array to store the RWF waveforms\n",
    "            pmtrwf = h5out.create_earray(h5out.root.RD, \"pmtrwf\", \n",
    "                                    atom=tables.Float32Atom(), \n",
    "                                    shape=(0, NPMT, PMTWL_FEE), \n",
    "                                    expectedrows=NEVENTS_DST)\n",
    "            \n",
    "            # create an extensible array to store the TWF waveforms\n",
    "            pmttwf = h5out.create_earray(h5out.root.RD, \"pmttwf\", \n",
    "                                    atom=tables.Float32Atom(), \n",
    "                                    shape=(0, NPMT, PMTWL_FEE), \n",
    "                                    expectedrows=NEVENTS_DST)\n",
    "            \n",
    "\n",
    "            sipmrwf = h5out.create_earray(h5out.root.RD, \"sipmrwf\", \n",
    "                                    atom=tables.Float32Atom(), \n",
    "                                    shape=(0, NSIPM, SIPMWL), \n",
    "                                    expectedrows=NEVENTS_DST)\n",
    "\n",
    "            # #create an extensible array to store the energy in PES of PMTs \n",
    "            # epmt = h5out.create_earray(h5out.root.RD, \"epmt\", \n",
    "            #                         atom=tables.FloatAtom(), \n",
    "            #                         shape=(0, NPMT), \n",
    "            #                         expectedrows=NEVENTS_DST)\n",
    "\n",
    "            # # create an extensible array to store the energy in PES of SiPMs \n",
    "            # esipm = h5out.create_earray(h5out.root.RD, \"esipm\", \n",
    "            #                         atom=tables.FloatAtom(), \n",
    "            #                         shape=(0, NSIPM), \n",
    "            #                         expectedrows=NEVENTS_DST)\n",
    "\n",
    "            \n",
    "            if NEVENTS > NEVENTS_DST and RUN_ALL == False:\n",
    "                print(\"\"\"\n",
    "                Refusing to run: you have requested\n",
    "                FIRST_EVT = {}\n",
    "                LAST_EVT  = {}\n",
    "                Thus you want to run over {} events\n",
    "                but the size of the DST is {} events.\n",
    "                Please change your choice or select RUN_ALL = TRUE\n",
    "                to run over the whole DST when this happens\n",
    "                \"\"\".format(FIRST_EVT,LAST_EVT,NEVENTS,NEVENTS_DST))\n",
    "                sys.exit(0)\n",
    "            elif  NEVENTS > NEVENTS_DST and RUN_ALL == True:\n",
    "                FIRST_EVT = 0\n",
    "                LAST_EVT = NEVENTS_DST\n",
    "                NEVENTS = NEVENTS_DST\n",
    "\n",
    "\n",
    "            for i in range(FIRST_EVT,LAST_EVT):\n",
    "                logger.info(\"-->event number ={}\".format(i))\n",
    "                logger.info(\"--> simulate_pmt_response: i ={}\".format(i))\n",
    "\n",
    "                #simulate PMT response and return an array with RWF\n",
    "                dataPMT = simulate_pmt_response(i,pmtrd_)\n",
    "\n",
    "                #convert to float\n",
    "                dataPMT.astype(float) \n",
    "                #TWF\n",
    "                \n",
    "                logger.info(\"--> rebin_signal: i ={}\".format(i))\n",
    "                truePMT = rebin_signal(i,pmtrd_, int(FP.time_DAQ))\n",
    "                truePMT.astype(float)\n",
    "                \n",
    "                logger.info(\"truePMT shape ={}\".format(truePMT.shape))\n",
    "                logger.info(\"dataPMT shape ={}\".format(dataPMT.shape))\n",
    "                \n",
    "                #RWF for pmts\n",
    "                pmtrwf.append(dataPMT.reshape(1, NPMT, PMTWL_FEE))\n",
    "                #pmtrd.append(dataPMT.reshape(1, NPMT, PMTWL))\n",
    "                \n",
    "                #TWF for pmts\n",
    "                pmttwf.append(truePMT.reshape(1, NPMT, PMTWL_FEE))\n",
    "                #pmtrd.append(dataPMT.reshape(1, NPMT, PMTWL))\n",
    "                   \n",
    "                #simulate SiPM response and return an array with new WF\n",
    "                dataSiPM = simulate_sipm_response(i,sipmrd_)\n",
    "                dataSiPM.astype(float)\n",
    "                \n",
    "                #append to SiPM EARRAY\n",
    "                sipmrwf.append(dataSiPM.reshape(1, NSIPM, SIPMWL))\n",
    "\n",
    "                # #fill ene_pmt vector\n",
    "                # enePMT = energy_pes(i, pmtrd_)\n",
    "                # #append to epmt EARRAY\n",
    "                # epmt.append(enePMT.reshape(1, NPMT))\n",
    "\n",
    "                # #fill ene_sipm vector\n",
    "                # eneSIPM = energy_pes(i, sipmrd_)\n",
    "                # esipm.append(eneSIPM.reshape(1, NSIPM))\n",
    "\n",
    "            pmtrwf.flush()\n",
    "            pmttwf.flush()\n",
    "            sipmrwf.flush()\n",
    "            #epmt.flush()\n",
    "            #esipm.flush()\n",
    "\n",
    "\n",
    "    print(\"Leaving Diomira. Safe travels!\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:root:Configuration Parameters (CFP) dictionary  = {'FIRST_EVT': 0, 'LAST_EVT': 3, 'FILE_OUT': 'WF_Na_ZLIB_test3_RWF.h5', 'PATH_OUT': '/Users/jjgomezcadenas/Documents/Development/NEXT/data/Waveforms/25ns/', ' END ': 1, 'CLIB': 'zlib', 'RUN_ALL': 1, 'PATH_IN': '/Users/jjgomezcadenas/Documents/Development/NEXT/data/Waveforms/WF-NA-ZLIB/', 'CLEVEL': 1, 'FILE_IN': 'WF_Na_1Kevts_comp1_chunk32k.h5'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Configuration Parameters (CFP) dictionary  = {'FIRST_EVT': 0, 'LAST_EVT': 3, 'FILE_OUT': 'WF_Na_ZLIB_test3_RWF.h5', 'PATH_OUT': '/Users/jjgomezcadenas/Documents/Development/NEXT/data/Waveforms/25ns/', ' END ': 1, 'CLIB': 'zlib', 'RUN_ALL': 1, 'PATH_IN': '/Users/jjgomezcadenas/Documents/Development/NEXT/data/Waveforms/WF-NA-ZLIB/', 'CLEVEL': 1, 'FILE_IN': 'WF_Na_1Kevts_comp1_chunk32k.h5'}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Leaving there and proceeding for three days toward the east, you reach Diomira, \n",
      "a city with sixty silver domes, bronze statues of all the gods, streets paved with lead, \n",
      "a crystal theater, a golden cock that crows every morning on a tower. \n",
      "All these beauties will already be familiar to the visitor, \n",
      "who has seen them also in other cities. \n",
      "But the special quality of this city for the man who arrives there on a September evening, \n",
      "when the days are growing shorter \n",
      "and the multicolored lamps are lighted all at once at the doors of the food stalls \n",
      "and from a terrace a woman's voice cries ooh!, is that he feels envy \n",
      "toward those who now believe they have once before lived an \n",
      "evening identical to this and who think they were happy, that time.\n",
      "\n",
      "        DIOMIRA:\n",
      "         1. Reads an MCRD file produced by art/centella, which stores MCRD \n",
      "         waveforms for PMTs (bins of 1 ns)\n",
      "        and the SiPMs (bins of 1 mus)\n",
      "            \n",
      "\n",
      "        2. Simulates the response of the energy plane in the PMTs MCRD, \n",
      "        and produces both RWF and TWF:\n",
      "        see: http://localhost:8931/notebooks/Nh5-Event-Model.ipynb#Reconstructed-Objects\n",
      "        \n",
      "            \n",
      "        3. Simulates the response of the tracking plane in the SiPMs MCRD and outputs\n",
      "            SiPM RWF (not yet implemented, for the time being simply copy the MCRD)\n",
      "\n",
      "        4. Add a table describing the FEE parameters used for simulation\n",
      "\n",
      "        5. Copies the tables on geometry, detector data and MC\n",
      "\n",
      "\n",
      "        \n",
      "\n",
      "  NEW FEE: DEFAULT PARAMETERS\n",
      "  PMT gain = 4.5e+06\n",
      "  sampling time: (fine) =    1.00 ns (DAQ) =   25.00 ns \n",
      "  decoupling capacitor =    6.20 nF\n",
      "  decoupling resistor = 2350.00 ohm\n",
      "  HPF frequency = 10923.47 Hz  W_HPF_fine = 1.1e-05 W_HPF_daq = 0.00027 \n",
      "  LPF frequency = 3000000.00 Hz  W_LPF_fine =   0.003 W_LPF_daq =   0.075 \n",
      "  noise =    0.70 mV\n",
      "  noise (adc) =    1.79\n",
      "  vots to adc factor =    2.56 \n",
      "  \n",
      "decoupling capacitors for energy plane = [ 6.02975448  6.22547194  6.0671337   6.22159457  6.29999787  6.09892384\n",
      "  6.18289435  6.21775591  6.19306671  6.30518792  6.20359891  6.31231192]\n",
      "Debug level = INFO\n",
      "INFO:root:input path =/Users/jjgomezcadenas/Documents/Development/NEXT/data/Waveforms/WF-NA-ZLIB/; output path = /Users/jjgomezcadenas/Documents/Development/NEXT/data/Waveforms/25ns/; file_in =WF_Na_1Kevts_comp1_chunk32k.h5 file_out =WF_Na_ZLIB_test3_RWF.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "input path =/Users/jjgomezcadenas/Documents/Development/NEXT/data/Waveforms/WF-NA-ZLIB/; output path = /Users/jjgomezcadenas/Documents/Development/NEXT/data/Waveforms/25ns/; file_in =WF_Na_1Kevts_comp1_chunk32k.h5 file_out =WF_Na_ZLIB_test3_RWF.h5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:root:first event = 0 last event = 3 nof events requested = 3 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "first event = 0 last event = 3 nof events requested = 3 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:root:Compression library = zlib Compression level = 1 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Compression library = zlib Compression level = 1 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:root:nof PMTs = 12 nof  SiPMs = 1792 nof events in input DST = 1000 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "nof PMTs = 12 nof  SiPMs = 1792 nof events in input DST = 1000 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:root:lof SiPM WF = 599999 lof PMT WF (MC) = 600 lof PMT WF (FEE) = 24000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "lof SiPM WF = 599999 lof PMT WF (MC) = 600 lof PMT WF (FEE) = 24000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "calling the cython version\n",
      "INFO:root:-->event number =0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "-->event number =0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:root:--> simulate_pmt_response: i =0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "--> simulate_pmt_response: i =0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:root:-->*cython::simulate_pmt_response, event =0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "-->*cython::simulate_pmt_response, event =0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:root:-->PMT number =0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "-->PMT number =0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:root:-->PMT number =1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "-->PMT number =1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:root:-->PMT number =2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "-->PMT number =2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:root:-->PMT number =3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "-->PMT number =3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:root:-->PMT number =4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "-->PMT number =4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:root:-->PMT number =5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "-->PMT number =5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:root:-->PMT number =6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "-->PMT number =6\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:root:-->PMT number =7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "-->PMT number =7\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:root:-->PMT number =8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "-->PMT number =8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:root:-->PMT number =9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "-->PMT number =9\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:root:-->PMT number =10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "-->PMT number =10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:root:-->PMT number =11\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "-->PMT number =11\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:root:--> rebin_signal: i =0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "--> rebin_signal: i =0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:root:-->*cython::rebin_signal, event =0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "-->*cython::rebin_signal, event =0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:root:-->PMT number =0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "-->PMT number =0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:root:-->*cython::rebin_pmt_array\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "-->*cython::rebin_pmt_array\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         45023 function calls (44994 primitive calls) in 3.261 seconds\n",
      "\n",
      "   Ordered by: internal time\n",
      "\n",
      "   ncalls  tottime  percall  cumtime  percall filename:lineno(function)\n",
      "        7    1.026    0.147    1.026    0.147 {method '_fill_col' of 'tables.tableextension.Row' objects}\n",
      "       12    0.613    0.051    0.613    0.051 {method 'normal' of 'mtrand.RandomState' objects}\n",
      "      156    0.573    0.004    0.573    0.004 {numpy.core.multiarray.correlate}\n",
      "        8    0.340    0.042    0.340    0.042 {method '_append_records' of 'tables.tableextension.Table' objects}\n",
      "       24    0.130    0.005    0.130    0.005 {scipy.signal.sigtools._linear_filter}\n",
      "        1    0.108    0.108    1.672    1.672 {_cython_magic_b3792d1d4fc96b0de24710bf906a8a85.simulate_pmt_response}\n",
      "       13    0.070    0.005    0.070    0.005 {method '_g_read_slice' of 'tables.hdf5extension.Array' objects}\n",
      "       12    0.064    0.005    0.808    0.067 FEE2.py:156(FEESignal)\n",
      "        2    0.064    0.032    0.064    0.032 {method '_close_file' of 'tables.hdf5extension.File' objects}\n",
      "        4    0.051    0.013    0.056    0.014 {method '_get_info' of 'tables.tableextension.Table' objects}\n",
      "       97    0.013    0.000    0.013    0.000 {numpy.core.multiarray.zeros}\n",
      "        1    0.009    0.009    0.009    0.009 {_cython_magic_b3792d1d4fc96b0de24710bf906a8a85.FEE_param_table}\n",
      "       12    0.009    0.001    0.420    0.035 shape_base.py:20(apply_along_axis)\n",
      "       36    0.008    0.000    0.559    0.016 signaltools.py:845(lfilter)\n",
      "        9    0.008    0.001    0.008    0.001 {method '_g_flush' of 'tables.hdf5extension.Leaf' objects}\n",
      "      350    0.007    0.000    0.007    0.000 {method 'send' of 'zmq.backend.cython.socket.Socket' objects}\n",
      "       12    0.007    0.001    0.440    0.037 FEE2.py:176(daqSignal)\n",
      "     1400    0.006    0.000    0.006    0.000 {method 'sub' of '_sre.SRE_Pattern' objects}\n",
      "      566    0.005    0.000    0.005    0.000 {method 'reduce' of 'numpy.ufunc' objects}\n",
      "      245    0.004    0.000    0.004    0.000 {numpy.core.multiarray.empty}\n",
      "      144    0.004    0.000    0.013    0.000 polynomial.py:32(poly)\n",
      "       50    0.004    0.000    0.045    0.001 iostream.py:151(flush)\n",
      "       48    0.003    0.000    0.006    0.000 filter_design.py:1620(_zpklp2hp)\n",
      "     2235    0.003    0.000    0.003    0.000 {numpy.core.multiarray.array}\n",
      "       43    0.003    0.000    0.003    0.000 {method '_g_get_objinfo' of 'tables.hdf5extension.Group' objects}\n",
      "      660    0.003    0.000    0.005    0.000 shape_base.py:9(atleast_1d)\n",
      "       62    0.003    0.000    0.005    0.000 {method '_g_setattr' of 'tables.hdf5extension.AttributeSet' objects}\n",
      "     1400    0.003    0.000    0.009    0.000 encoder.py:33(encode_basestring)\n",
      "       91    0.003    0.000    0.005    0.000 atom.py:409(from_kind)\n",
      "        2    0.003    0.001    0.003    0.001 {method '_g_new' of 'tables.hdf5extension.File' objects}\n",
      "       14    0.002    0.000    0.002    0.000 {method '_g_close' of 'tables.hdf5extension.Leaf' objects}\n",
      "        5    0.002    0.000    0.003    0.001 {method '_create_table' of 'tables.tableextension.Table' objects}\n",
      "       36    0.002    0.000    0.005    0.000 filter_design.py:1517(_zpkbilinear)\n",
      "      200    0.002    0.000    0.012    0.000 encoder.py:212(iterencode)\n",
      "       72    0.002    0.000    0.003    0.000 filter_design.py:2863(buttap)\n",
      "     4039    0.002    0.000    0.002    0.000 {isinstance}\n",
      "       72    0.002    0.000    0.034    0.000 filter_design.py:1327(iirfilter)\n",
      "       87    0.002    0.000    0.003    0.000 fromnumeric.py:1892(any)\n",
      "        1    0.002    0.002    0.002    0.002 parsers.py:1197(__init__)\n",
      "       50    0.002    0.000    0.002    0.000 {posix.urandom}\n",
      "       10    0.002    0.000    0.002    0.000 common.py:1111(_possibly_infer_to_datetimelike)\n",
      "       12    0.002    0.000    0.004    0.000 fir_filter_design.py:138(firwin)\n",
      "       50    0.001    0.000    0.002    0.000 uuid.py:103(__init__)\n",
      "        5    0.001    0.000    0.016    0.003 table.py:1027(_g_create)\n",
      "      650    0.001    0.000    0.001    0.000 traitlets.py:499(get)\n",
      "       61    0.001    0.000    0.001    0.000 {method '_g_getattr' of 'tables.hdf5extension.AttributeSet' objects}\n",
      "      200    0.001    0.000    0.015    0.000 __init__.py:193(dumps)\n",
      "       50    0.001    0.000    0.037    0.001 session.py:600(send)\n",
      "      629    0.001    0.000    0.002    0.000 {hasattr}\n",
      "     1112    0.001    0.000    0.002    0.000 numeric.py:484(asanyarray)\n",
      "      345    0.001    0.000    0.004    0.000 fromnumeric.py:2395(prod)\n",
      "       72    0.001    0.000    0.015    0.000 filter_design.py:594(zpk2tf)\n",
      "      121    0.001    0.000    0.003    0.000 atom.py:493(__init__)\n",
      "      156    0.001    0.000    0.574    0.004 numeric.py:918(convolve)\n",
      "      250    0.001    0.000    0.001    0.000 {method 'update' of '_hashlib.HASH' objects}\n",
      "       50    0.001    0.000    0.001    0.000 {zmq.backend.cython._poll.zmq_poll}\n",
      "      650    0.001    0.000    0.002    0.000 traitlets.py:518(__get__)\n",
      "      246    0.001    0.000    0.003    0.000 attributeset.py:61(issysattrname)\n",
      "        6    0.001    0.000    0.001    0.000 {method '_g_get_lchild_attr' of 'tables.hdf5extension.Group' objects}\n",
      "       50    0.001    0.000    0.008    0.000 socket.py:289(send_multipart)\n",
      "4122/4114    0.001    0.000    0.001    0.000 {len}\n",
      "      144    0.001    0.000    0.001    0.000 type_check.py:18(mintypecode)\n",
      "       50    0.001    0.000    0.001    0.000 __init__.py:715(format)\n",
      "      200    0.001    0.000    0.013    0.000 encoder.py:186(encode)\n",
      "       25    0.001    0.000    0.001    0.000 __init__.py:237(__init__)\n",
      "       13    0.001    0.000    0.001    0.000 array.py:370(_interpret_indexing)\n",
      "       50    0.001    0.000    0.020    0.000 session.py:541(serialize)\n",
      "        1    0.001    0.001    0.002    0.002 FEParam.py:95(print_FEE)\n",
      "      121    0.001    0.000    0.001    0.000 atom.py:116(_normalize_shape)\n",
      "      100    0.001    0.000    0.001    0.000 __init__.py:695(acquire)\n",
      "       50    0.001    0.000    0.047    0.001 __init__.py:830(flush)\n",
      "      200    0.001    0.000    0.016    0.000 jsonapi.py:31(dumps)\n",
      "        1    0.001    0.001    0.008    0.008 {_cython_magic_b3792d1d4fc96b0de24710bf906a8a85.rebin_signal}\n",
      "       50    0.001    0.000    0.050    0.001 __init__.py:841(emit)\n",
      "       50    0.001    0.000    0.001    0.000 attrsettr.py:35(__getattr__)\n",
      "        9    0.001    0.000    0.002    0.000 table.py:875(_g_post_init_hook)\n",
      "       62    0.001    0.000    0.009    0.000 attributeset.py:375(_g__setattr)\n",
      "      177    0.001    0.000    0.001    0.000 file.py:382(register_node)\n",
      "        5    0.001    0.000    0.002    0.000 description.py:443(__init__)\n",
      "     1467    0.001    0.000    0.001    0.000 {method 'append' of 'list' objects}\n",
      "       21    0.001    0.000    0.083    0.004 node.py:203(__init__)\n",
      "      169    0.001    0.000    0.001    0.000 {method 'astype' of 'numpy.ndarray' objects}\n",
      "        6    0.001    0.000    0.001    0.000 {tables.utilsextension.which_class}\n",
      "        3    0.001    0.000    0.001    0.000 {method '_create_carray' of 'tables.hdf5extension.Array' objects}\n",
      "      471    0.001    0.000    0.001    0.000 description.py:677(_f_walk)\n",
      "       68    0.001    0.000    0.001    0.000 table.py:3487(__init__)\n",
      "       25    0.000    0.000    0.055    0.002 __init__.py:1149(info)\n",
      "      200    0.000    0.000    0.000    0.000 {method 'join' of 'str' objects}\n",
      "      291    0.000    0.000    0.000    0.000 {range}\n",
      "      200    0.000    0.000    0.000    0.000 encoder.py:101(__init__)\n",
      "       71    0.000    0.000    0.003    0.000 attributeset.py:282(__getattr__)\n",
      "       50    0.000    0.000    0.002    0.000 session.py:526(sign)\n",
      "      100    0.000    0.000    0.001    0.000 threading.py:187(release)\n",
      "      108    0.000    0.000    0.000    0.000 {method 'reshape' of 'numpy.ndarray' objects}\n",
      "       50    0.000    0.000    0.006    0.000 session.py:507(msg)\n",
      "       62    0.000    0.000    0.001    0.000 iostream.py:207(write)\n",
      "      147    0.000    0.000    0.000    0.000 {method 'compress' of 'numpy.ndarray' objects}\n",
      "      472    0.000    0.000    0.001    0.000 {getattr}\n",
      "      102    0.000    0.000    0.000    0.000 {method 'clear' of 'dict' objects}\n",
      "      180    0.000    0.000    0.000    0.000 {numpy.core.multiarray.copyto}\n",
      "      150    0.000    0.000    0.000    0.000 {method 'encode' of 'unicode' objects}\n",
      "      108    0.000    0.000    0.000    0.000 {numpy.core.multiarray.concatenate}\n",
      "      136    0.000    0.000    0.000    0.000 {numpy.core.multiarray.arange}\n",
      "       36    0.000    0.000    0.035    0.001 FEE2.py:55(__init__)\n",
      "       60    0.000    0.000    0.000    0.000 {map}\n",
      "       50    0.000    0.000    0.002    0.000 iostream.py:123(_flush_from_subprocesses)\n",
      "        1    0.000    0.000    3.261    3.261 <ipython-input-26-1b77e47d2505>:37(DIOMIRA)\n",
      "      121    0.000    0.000    0.001    0.000 atom.py:139(_normalize_default)\n",
      "  159/155    0.000    0.000    0.066    0.000 file.py:408(get_node)\n",
      "      217    0.000    0.000    0.000    0.000 group.py:843(__setattr__)\n",
      "      175    0.000    0.000    0.002    0.000 file.py:395(cache_node)\n",
      "       25    0.000    0.000    0.054    0.002 __init__.py:1259(_log)\n",
      "      200    0.000    0.000    0.016    0.000 session.py:94(<lambda>)\n",
      "       50    0.000    0.000    0.000    0.000 {built-in method now}\n",
      "      136    0.000    0.000    0.000    0.000 table.py:3222(_g_col)\n",
      "      212    0.000    0.000    0.000    0.000 {method 'pop' of 'tables.lrucacheextension.NodeCache' objects}\n",
      "      144    0.000    0.000    0.001    0.000 function_base.py:1807(sort_complex)\n",
      "       20    0.000    0.000    0.004    0.000 attributeset.py:200(__init__)\n",
      "        9    0.000    0.000    0.080    0.009 table.py:705(__init__)\n",
      "      100    0.000    0.000    0.001    0.000 threading.py:147(acquire)\n",
      "       50    0.000    0.000    0.000    0.000 session.py:211(extract_header)\n",
      "      200    0.000    0.000    0.000    0.000 threading.py:64(_note)\n",
      "        1    0.000    0.000    0.000    0.000 {method 'read' of 'pandas.parser.TextReader' objects}\n",
      "        5    0.000    0.000    0.000    0.000 {method '_close_append' of 'tables.tableextension.Table' objects}\n",
      "       50    0.000    0.000    0.001    0.000 __init__.py:452(format)\n",
      "       12    0.000    0.000    0.035    0.003 FEE2.py:116(__init__)\n",
      "       50    0.000    0.000    0.005    0.000 session.py:504(msg_header)\n",
      "       24    0.000    0.000    0.000    0.000 function_base.py:3262(sinc)\n",
      "      180    0.000    0.000    0.001    0.000 numeric.py:148(ones)\n",
      "       62    0.000    0.000    0.000    0.000 {_codecs.utf_8_decode}\n",
      "        2    0.000    0.000    0.004    0.002 file.py:748(__init__)\n",
      "       41    0.000    0.000    0.000    0.000 {method '__reduce_ex__' of 'object' objects}\n",
      "       99    0.000    0.000    0.000    0.000 encoder.py:37(replace)\n",
      "       50    0.000    0.000    0.000    0.000 hmac.py:88(copy)\n",
      "      255    0.000    0.000    0.001    0.000 numeric.py:414(asarray)\n",
      "       24    0.000    0.000    0.000    0.000 function_base.py:9(linspace)\n",
      "       50    0.000    0.000    0.051    0.001 __init__.py:738(handle)\n",
      "       12    0.000    0.000    0.001    0.000 SPE.py:19(__init__)\n",
      "      516    0.000    0.000    0.000    0.000 {issubclass}\n",
      "        4    0.000    0.000    1.380    0.345 leaf.py:428(_g_copy)\n",
      "        9    0.000    0.000    0.001    0.000 table.py:1142(_cache_description_data)\n",
      "      192    0.000    0.000    0.000    0.000 weakref.py:88(__contains__)\n",
      "       27    0.000    0.000    0.001    0.000 atom.py:565(_get_init_args)\n",
      "       13    0.000    0.000    0.076    0.006 array.py:627(__getitem__)\n",
      "      338    0.000    0.000    0.000    0.000 {method 'sort' of 'list' objects}\n",
      "       24    0.000    0.000    0.131    0.005 FEE2.py:80(FilterPulse)\n",
      "       84    0.000    0.000    0.001    0.000 function_base.py:4534(append)\n",
      "        9    0.000    0.000    0.000    0.000 table.py:1016(_get_enum_map)\n",
      "       45    0.000    0.000    0.000    0.000 atom.py:55(split_type)\n",
      "       50    0.000    0.000    0.004    0.000 uuid.py:582(uuid4)\n",
      "       10    0.000    0.000    0.002    0.000 frame.py:1973(__getitem__)\n",
      "      123    0.000    0.000    0.001    0.000 attributeset.py:193(_g_getnode)\n",
      "       24    0.000    0.000    0.000    0.000 filter_design.py:1567(_zpklp2lp)\n",
      "       25    0.000    0.000    0.000    0.000 __init__.py:1225(findCaller)\n",
      "       12    0.000    0.000    0.433    0.036 signaltools.py:2634(decimate)\n",
      "       62    0.000    0.000    0.001    0.000 {method 'decode' of 'str' objects}\n",
      "        4    0.000    0.000    0.000    0.000 {tables.utilsextension.get_filters}\n",
      "      156    0.000    0.000    0.000    0.000 numeric.py:846(_mode_from_name)\n",
      "       13    0.000    0.000    0.074    0.006 array.py:758(_read_slice)\n",
      "       27    0.000    0.000    0.000    0.000 inspect.py:744(getargs)\n",
      "       50    0.000    0.000    0.000    0.000 uuid.py:199(__str__)\n",
      "        1    0.000    0.000    0.002    0.002 internals.py:4007(form_blocks)\n",
      "       25    0.000    0.000    0.052    0.002 __init__.py:1312(callHandlers)\n",
      "        3    0.000    0.000    0.000    0.000 arrayprint.py:543(fillFormat)\n",
      "       24    0.000    0.000    0.613    0.026 FEE2.py:187(FEENoise)\n",
      "       50    0.000    0.000    0.004    0.000 session.py:452(msg_id)\n",
      "       21    0.000    0.000    0.001    0.000 node.py:355(_g_set_location)\n",
      "      102    0.000    0.000    0.002    0.000 atom.py:668(__init__)\n",
      "      163    0.000    0.000    0.000    0.000 {method 'match' of '_sre.SRE_Pattern' objects}\n",
      "      345    0.000    0.000    0.003    0.000 _methods.py:34(_prod)\n",
      "      424    0.000    0.000    0.000    0.000 {method 'startswith' of 'str' objects}\n",
      "       41    0.000    0.000    0.000    0.000 copy.py:306(_reconstruct)\n",
      "       12    0.000    0.000    0.000    0.000 windows.py:859(hamming)\n",
      "       85    0.000    0.000    0.000    0.000 fromnumeric.py:1383(ravel)\n",
      "       12    0.000    0.000    0.000    0.000 function_base.py:1518(diff)\n",
      "        2    0.000    0.000    0.000    0.000 {method '_open_array' of 'tables.hdf5extension.Array' objects}\n",
      "       27    0.000    0.000    0.002    0.000 description.py:108(from_atom)\n",
      "        5    0.000    0.000    0.000    0.000 table.py:596(row)\n",
      "       12    0.000    0.000    0.175    0.015 SPE.py:91(SpePulseFromVectorPE)\n",
      "      100    0.000    0.000    0.001    0.000 __init__.py:702(release)\n",
      "  173/169    0.000    0.000    0.067    0.000 file.py:1549(_get_node)\n",
      "       12    0.000    0.000    0.000    0.000 windows.py:1610(get_window)\n",
      "       10    0.000    0.000    0.002    0.000 common.py:1011(_possibly_cast_to_datetime)\n",
      "       72    0.000    0.000    0.034    0.000 filter_design.py:1824(butter)\n",
      "       12    0.000    0.000    0.001    0.000 group.py:502(_g_refnode)\n",
      "       43    0.000    0.000    0.003    0.000 group.py:394(_g_check_has_child)\n",
      "       12    0.000    0.000    0.000    0.000 arrayprint.py:594(__call__)\n",
      "       12    0.000    0.000    0.131    0.011 FEE2.py:131(Filter)\n",
      "       50    0.000    0.000    0.000    0.000 iostream.py:96(_is_master_thread)\n",
      "       76    0.000    0.000    0.001    0.000 fromnumeric.py:1875(alltrue)\n",
      "       12    0.000    0.000    0.000    0.000 {pandas.lib.infer_dtype}\n",
      "    14/10    0.000    0.000    0.065    0.006 group.py:1174(_g_load_child)\n",
      "       27    0.000    0.000    0.001    0.000 inspect.py:804(getargspec)\n",
      "       62    0.000    0.000    0.002    0.000 atom.py:354(from_dtype)\n",
      "       13    0.000    0.000    0.000    0.000 leaf.py:211(<lambda>)\n",
      "      3/2    0.000    0.000    0.001    0.000 base.py:124(__new__)\n",
      "      162    0.000    0.000    0.000    0.000 iostream.py:93(_is_master_process)\n",
      "        4    0.000    0.000    0.059    0.015 table.py:1083(_g_open)\n",
      "       53    0.000    0.000    0.000    0.000 path.py:69(check_name_validity)\n",
      "      372    0.000    0.000    0.000    0.000 {method 'lower' of 'str' objects}\n",
      "        4    0.000    0.000    0.000    0.000 {method '_g_create' of 'tables.hdf5extension.Group' objects}\n",
      "       50    0.000    0.000    0.000    0.000 {method 'isoformat' of 'datetime.datetime' objects}\n",
      "       50    0.000    0.000    0.000    0.000 iostream.py:238(_flush_buffer)\n",
      "      150    0.000    0.000    0.000    0.000 {method 'copy' of '_hashlib.HASH' objects}\n",
      "  134/129    0.000    0.000    0.005    0.000 utils.py:240(newfget)\n",
      "        5    0.000    0.000    0.000    0.000 description.py:599(_g_set_path_names)\n",
      "      309    0.000    0.000    0.000    0.000 weakref.py:76(__getitem__)\n",
      "        4    0.000    0.000    1.366    0.342 table.py:2904(_g_copy_rows_optim)\n",
      "       50    0.000    0.000    0.000    0.000 iostream.py:247(_new_buffer)\n",
      "       50    0.000    0.000    0.001    0.000 poll.py:77(poll)\n",
      "      200    0.000    0.000    0.001    0.000 hmac.py:83(update)\n",
      "       62    0.000    0.000    0.000    0.000 {method 'write' of '_io.StringIO' objects}\n",
      "       50    0.000    0.000    0.001    0.000 session.py:206(msg_header)\n",
      "       41    0.000    0.000    0.001    0.000 copy.py:66(copy)\n",
      "       50    0.000    0.000    0.000    0.000 __init__.py:312(getMessage)\n",
      "       88    0.000    0.000    0.001    0.000 {method 'any' of 'numpy.ndarray' objects}\n",
      "        1    0.000    0.000    0.008    0.008 parsers.py:416(parser_f)\n",
      "      144    0.000    0.000    0.001    0.000 fromnumeric.py:1619(compress)\n",
      "       24    0.000    0.000    0.000    0.000 {numpy.core.multiarray.where}\n",
      "       30    0.000    0.000    0.000    0.000 generic.py:2674(__setattr__)\n",
      "       20    0.000    0.000    0.000    0.000 base.py:1233(__contains__)\n",
      "      112    0.000    0.000    0.000    0.000 iostream.py:102(_check_mp_mode)\n",
      "        7    0.000    0.000    0.001    0.000 leaf.py:320(_calc_chunkshape)\n",
      "      142    0.000    0.000    0.000    0.000 generic.py:7(_check)\n",
      "       23    0.000    0.000    0.000    0.000 node.py:439(_g_del_location)\n",
      "        9    0.000    0.000    0.001    0.000 table.py:3161(__init__)\n",
      "      144    0.000    0.000    0.000    0.000 {method 'index' of 'str' objects}\n",
      "       30    0.000    0.000    0.000    0.000 leaf.py:390(_process_range)\n",
      "       41    0.000    0.000    0.000    0.000 atom.py:483(<lambda>)\n",
      "       10    0.000    0.000    0.000    0.000 internals.py:3312(iget)\n",
      "       25    0.000    0.000    0.001    0.000 node.py:482(_f_close)\n",
      "        9    0.000    0.000    0.000    0.000 table.py:3343(_g_close)\n",
      "       76    0.000    0.000    0.001    0.000 {method 'all' of 'numpy.ndarray' objects}\n",
      "        1    0.000    0.000    0.000    0.000 internals.py:2674(_rebuild_blknos_and_blklocs)\n",
      "       12    0.000    0.000    0.000    0.000 numeric.py:2064(isscalar)\n",
      "      132    0.000    0.000    0.000    0.000 {method 'rfind' of 'str' objects}\n",
      "       13    0.000    0.000    0.067    0.005 group.py:697(_f_get_child)\n",
      "       27    0.000    0.000    0.001    0.000 description.py:196(__init__)\n",
      "       50    0.000    0.000    0.000    0.000 jsonutil.py:75(date_default)\n",
      "        3    0.000    0.000    0.000    0.000 {method '_g_get_gchild_attr' of 'tables.hdf5extension.Group' objects}\n",
      "        8    0.000    0.000    0.013    0.002 file.py:499(_close_nodes)\n",
      "       19    0.000    0.000    0.000    0.000 atom.py:609(__init__)\n",
      "       84    0.000    0.000    0.000    0.000 type_check.py:107(real)\n",
      "        6    0.000    0.000    0.001    0.000 group.py:306(_g_get_child_leaf_class)\n",
      "       29    0.000    0.000    0.000    0.000 path.py:122(join_path)\n",
      "       25    0.000    0.000    0.001    0.000 __init__.py:1246(makeRecord)\n",
      "       10    0.000    0.000    0.000    0.000 series.py:120(__init__)\n",
      "       79    0.000    0.000    0.000    0.000 node.py:342(_g_check_open)\n",
      "       50    0.000    0.000    0.000    0.000 {locals}\n",
      "       10    0.000    0.000    0.003    0.000 series.py:2787(_sanitize_array)\n",
      "       87    0.000    0.000    0.000    0.000 {method 'ravel' of 'numpy.ndarray' objects}\n",
      "       12    0.000    0.000    0.000    0.000 {method 'format' of 'str' objects}\n",
      "       10    0.000    0.000    0.001    0.000 base.py:1957(get_value)\n",
      "       25    0.000    0.000    0.000    0.000 __init__.py:1352(isEnabledFor)\n",
      "       25    0.000    0.000    0.000    0.000 __init__.py:148(getLevelName)\n",
      "       50    0.000    0.000    0.000    0.000 hmac.py:100(_current)\n",
      "       25    0.000    0.000    0.052    0.002 __init__.py:1280(handle)\n",
      "       45    0.000    0.000    0.002    0.000 atom.py:382(from_type)\n",
      "       12    0.000    0.000    0.433    0.036 FEE2.py:21(down_scale_signal_)\n",
      "        5    0.000    0.000    0.000    0.000 {method '_g_list_group' of 'tables.hdf5extension.Group' objects}\n",
      "      108    0.000    0.000    0.000    0.000 filter_design.py:1503(_relative_degree)\n",
      "       12    0.000    0.000    0.000    0.000 internals.py:2482(make_block)\n",
      "        5    0.000    0.000    0.000    0.000 leaf.py:360(_calc_nrowsinbuf)\n",
      "       20    0.000    0.000    0.000    0.000 {method '_g_list_attr' of 'tables.hdf5extension.AttributeSet' objects}\n",
      "       50    0.000    0.000    0.000    0.000 {method 'hexdigest' of '_hashlib.HASH' objects}\n",
      "       88    0.000    0.000    0.001    0.000 _methods.py:37(_any)\n",
      "       23    0.000    0.000    0.000    0.000 weakref.py:105(__setitem__)\n",
      "       42    0.000    0.000    0.000    0.000 {pandas.lib.values_from_object}\n",
      "      146    0.000    0.000    0.000    0.000 {method 'split' of 'str' objects}\n",
      "       75    0.000    0.000    0.000    0.000 threading.py:1143(currentThread)\n",
      "       62    0.000    0.000    0.000    0.000 utf_8.py:15(decode)\n",
      "       72    0.000    0.000    0.000    0.000 {method 'copy' of 'numpy.ndarray' objects}\n",
      "       50    0.000    0.000    0.000    0.000 {method 'digest' of '_hashlib.HASH' objects}\n",
      "       12    0.000    0.000    0.175    0.015 signaltools.py:392(convolve)\n",
      "       30    0.000    0.000    0.000    0.000 numeric.py:2576(seterr)\n",
      "        2    0.000    0.000    0.000    0.000 internals.py:4168(_stack_arrays)\n",
      "        1    0.000    0.000    0.003    0.003 Configure.py:10(cdf_to_dict)\n",
      "        5    0.000    0.000    0.000    0.000 {method '_g_open' of 'tables.hdf5extension.Group' objects}\n",
      "       17    0.000    0.000    0.001    0.000 file.py:1561(get_node)\n",
      "       45    0.000    0.000    0.000    0.000 dtypes.py:74(is_dtype)\n",
      "       75    0.000    0.000    0.000    0.000 __init__.py:599(filter)\n",
      "       50    0.000    0.000    0.000    0.000 __init__.py:446(usesTime)\n",
      "      124    0.000    0.000    0.000    0.000 {built-in method __new__ of type object at 0x10c93dc18}\n",
      "        3    0.000    0.000    0.000    0.000 common.py:1380(_asarray_tuplesafe)\n",
      "      300    0.000    0.000    0.000    0.000 {thread.get_ident}\n",
      "        1    0.000    0.000    0.008    0.008 parsers.py:272(_read)\n",
      "        9    0.000    0.000    0.000    0.000 table.py:950(_calc_nrowsinbuf)\n",
      "       14    0.000    0.000    0.081    0.006 leaf.py:231(__init__)\n",
      "        2    0.000    0.000    0.000    0.000 frame.py:5244(extract_index)\n",
      "        1    0.000    0.000    0.001    0.001 internals.py:2578(__init__)\n",
      "       14    0.000    0.000    0.000    0.000 leaf.py:297(_g_post_init_hook)\n",
      "        7    0.000    0.000    0.000    0.000 {posix.access}\n",
      "       10    0.000    0.000    0.001    0.000 frame.py:2331(_box_item_values)\n",
      "        1    0.000    0.000    0.013    0.013 Configure.py:59(configure)\n",
      "       72    0.000    0.000    0.000    0.000 fromnumeric.py:2659(size)\n",
      "        5    0.000    0.000    0.002    0.000 carray.py:133(__init__)\n",
      "       10    0.000    0.000    0.002    0.000 generic.py:1345(_get_item_cache)\n",
      "       15    0.000    0.000    0.000    0.000 fromnumeric.py:1743(sum)\n",
      "       50    0.000    0.000    0.000    0.000 {method 'find' of 'str' objects}\n",
      "       50    0.000    0.000    0.000    0.000 {method 'acquire' of 'thread.lock' objects}\n",
      "       77    0.000    0.000    0.000    0.000 {max}\n",
      "       50    0.000    0.000    0.000    0.000 hmac.py:119(hexdigest)\n",
      "      255    0.000    0.000    0.000    0.000 {method 'get' of 'dict' objects}\n",
      "       10    0.000    0.000    0.001    0.000 internals.py:3283(get)\n",
      "        4    0.000    0.000    1.379    0.345 table.py:2942(_g_copy_with_stats)\n",
      "       12    0.000    0.000    0.000    0.000 internals.py:77(__init__)\n",
      "       12    0.000    0.000    0.000    0.000 internals.py:191(mgr_locs)\n",
      "       76    0.000    0.000    0.001    0.000 _methods.py:40(_all)\n",
      "       10    0.000    0.000    0.000    0.000 {method 'get_value' of 'pandas.index.IndexEngine' objects}\n",
      "       30    0.000    0.000    0.000    0.000 path.py:154(split_path)\n",
      "        9    0.000    0.000    0.002    0.000 group.py:240(_g_post_init_hook)\n",
      "        5    0.000    0.000    0.000    0.000 group.py:346(_g_add_children_names)\n",
      "       12    0.000    0.000    0.000    0.000 fromnumeric.py:1843(product)\n",
      "       23    0.000    0.000    0.000    0.000 weakref.py:282(__init__)\n",
      "       18    0.000    0.000    0.000    0.000 table.py:1007(_get_type_col_names)\n",
      "       10    0.000    0.000    0.000    0.000 internals.py:3778(__init__)\n",
      "       12    0.000    0.000    0.000    0.000 shape_base.py:232(hstack)\n",
      "        1    0.000    0.000    0.000    0.000 {pandas.lib.clean_index_list}\n",
      "        1    0.000    0.000    0.003    0.003 frame.py:5521(_homogenize)\n",
      "       18    0.000    0.000    0.068    0.004 group.py:825(__getattr__)\n",
      "       20    0.000    0.000    0.004    0.000 node.py:166(_v_attrs)\n",
      "       11    0.000    0.000    0.000    0.000 generic.py:94(__init__)\n",
      "       36    0.000    0.000    0.000    0.000 {numpy.core.multiarray.result_type}\n",
      "       25    0.000    0.000    0.000    0.000 posixpath.py:97(splitext)\n",
      "        2    0.000    0.000    0.000    0.000 numeric.py:607(require)\n",
      "        9    0.000    0.000    0.000    0.000 table.py:633(_v_wdflts)\n",
      "        2    0.000    0.000    0.000    0.000 file.py:364(__init__)\n",
      "       30    0.000    0.000    0.000    0.000 numeric.py:2676(geterr)\n",
      "        5    0.000    0.000    0.000    0.000 description.py:579(_g_set_nested_names_descr)\n",
      "        1    0.000    0.000    0.001    0.001 arrayprint.py:237(_array2string)\n",
      "       22    0.000    0.000    0.000    0.000 common.py:1736(is_categorical_dtype)\n",
      "       12    0.000    0.000    0.398    0.033 signaltools.py:957(<lambda>)\n",
      "      102    0.000    0.000    0.000    0.000 {method 'extend' of 'list' objects}\n",
      "       25    0.000    0.000    0.000    0.000 node.py:849(_g_check_group)\n",
      "        2    0.000    0.000    0.013    0.006 file.py:530(close_subtree)\n",
      "       10    0.000    0.000    0.002    0.000 series.py:2804(_try_cast)\n",
      "        7    0.000    0.000    0.003    0.000 group.py:207(__init__)\n",
      "      139    0.000    0.000    0.000    0.000 atom.py:136(<genexpr>)\n",
      "      144    0.000    0.000    0.000    0.000 {method 'sort' of 'numpy.ndarray' objects}\n",
      "        2    0.000    0.000    0.000    0.000 file.py:108(add)\n",
      "        1    0.000    0.000    0.000    0.000 internals.py:4136(_multi_blockify)\n",
      "       16    0.000    0.000    0.000    0.000 group.py:426(__contains__)\n",
      "       82    0.000    0.000    0.000    0.000 atom.py:585(<genexpr>)\n",
      "      237    0.000    0.000    0.000    0.000 {posix.getpid}\n",
      "       25    0.000    0.000    0.000    0.000 weakref.py:199(pop)\n",
      "        2    0.000    0.000    0.000    0.000 weakref.py:47(__init__)\n",
      "       14    0.000    0.000    0.003    0.000 leaf.py:733(_f_close)\n",
      "       87    0.000    0.000    0.000    0.000 {method 'endswith' of 'str' objects}\n",
      "        2    0.000    0.000    0.077    0.039 file.py:2703(close)\n",
      "        8    0.000    0.000    0.000    0.000 array.py:113(_getrowsize)\n",
      "       10    0.000    0.000    0.001    0.000 series.py:580(__getitem__)\n",
      "       10    0.000    0.000    0.000    0.000 numeric.py:133(_convert_scalar_indexer)\n",
      "       25    0.000    0.000    0.000    0.000 posixpath.py:112(basename)\n",
      "       24    0.000    0.000    0.000    0.000 range.py:435(__len__)\n",
      "       23    0.000    0.000    0.000    0.000 weakref.py:277(__new__)\n",
      "       50    0.000    0.000    0.000    0.000 {method 'close' of '_io.StringIO' objects}\n",
      "       20    0.000    0.000    0.000    0.000 {method 'get_loc' of 'pandas.index.IndexEngine' objects}\n",
      "       52    0.000    0.000    0.000    0.000 {method 'upper' of 'str' objects}\n",
      "       24    0.000    0.000    0.000    0.000 arrayprint.py:628(_digits)\n",
      "        2    0.000    0.000    0.000    0.000 file.py:837(__get_root_group)\n",
      "       10    0.000    0.000    0.000    0.000 series.py:270(_set_axis)\n",
      "        1    0.000    0.000    0.006    0.006 frame.py:307(_init_dict)\n",
      "       87    0.000    0.000    0.000    0.000 {time.time}\n",
      "        9    0.000    0.000    0.000    0.000 {method '_g_close_group' of 'tables.hdf5extension.Group' objects}\n",
      "       10    0.000    0.000    0.000    0.000 {pandas.lib.checknull}\n",
      "        9    0.000    0.000    0.010    0.001 table.py:3063(_f_close)\n",
      "        6    0.000    0.000    0.000    0.000 internals.py:1657(__init__)\n",
      "        2    0.000    0.000    0.000    0.000 group.py:1132(__init__)\n",
      "       25    0.000    0.000    0.000    0.000 __init__.py:70(<lambda>)\n",
      "      100    0.000    0.000    0.000    0.000 {method 'pop' of 'list' objects}\n",
      "       12    0.000    0.000    0.000    0.000 {method 'take' of 'numpy.ndarray' objects}\n",
      "        3    0.000    0.000    0.001    0.000 earray.py:155(_g_create)\n",
      "       10    0.000    0.000    0.001    0.000 series.py:236(from_array)\n",
      "        1    0.000    0.000    0.005    0.005 frame.py:5224(_arrays_to_mgr)\n",
      "        7    0.000    0.000    0.000    0.000 leaf.py:50(calc_chunksize)\n",
      "        1    0.000    0.000    0.000    0.000 parsers.py:1312(read)\n",
      "        1    0.000    0.000    0.000    0.000 common.py:272(array_equivalent)\n",
      "       50    0.000    0.000    0.000    0.000 threading.py:974(ident)\n",
      "        9    0.000    0.000    0.009    0.001 table.py:3003(flush)\n",
      "        4    0.000    0.000    0.000    0.000 {posix.stat}\n",
      "       20    0.000    0.000    0.000    0.000 base.py:1915(get_loc)\n",
      "       27    0.000    0.000    0.000    0.000 atom.py:321(prefix)\n",
      "       25    0.000    0.000    0.000    0.000 {sys._getframe}\n",
      "       24    0.000    0.000    0.000    0.000 {method 'tolist' of 'numpy.ndarray' objects}\n",
      "       50    0.000    0.000    0.000    0.000 {method 'count' of 'list' objects}\n",
      "        1    0.000    0.000    0.000    0.000 {pandas.lib.list_to_object_array}\n",
      "        2    0.000    0.000    0.004    0.002 file.py:222(open_file)\n",
      "        4    0.000    0.000    0.000    0.000 filters.py:161(_from_leaf)\n",
      "       68    0.000    0.000    0.000    0.000 table.py:3834(close)\n",
      "       43    0.000    0.000    0.000    0.000 {method 'update' of 'dict' objects}\n",
      "       10    0.000    0.000    0.000    0.000 base.py:972(_convert_scalar_indexer)\n",
      "       10    0.000    0.000    0.001    0.000 frame.py:2338(_box_col_values)\n",
      "       10    0.000    0.000    0.000    0.000 series.py:302(name)\n",
      "        4    0.000    0.000    1.380    0.345 node.py:745(_f_copy)\n",
      "       11    0.000    0.000    0.000    0.000 group.py:906(_g_close)\n",
      "        1    0.000    0.000    0.000    0.000 arrayprint.py:458(_formatArray)\n",
      "       30    0.000    0.000    0.000    0.000 common.py:1763(is_list_like)\n",
      "      102    0.000    0.000    0.000    0.000 {method 'isupper' of 'str' objects}\n",
      "       27    0.000    0.000    0.000    0.000 inspect.py:67(ismethod)\n",
      "       12    0.000    0.000    0.000    0.000 {method 'put' of 'numpy.ndarray' objects}\n",
      "      139    0.000    0.000    0.000    0.000 atom.py:502(<genexpr>)\n",
      "       25    0.000    0.000    0.000    0.000 genericpath.py:93(_splitext)\n",
      "       25    0.000    0.000    0.000    0.000 __init__.py:1338(getEffectiveLevel)\n",
      "        1    0.000    0.000    0.000    0.000 internals.py:2799(_verify_integrity)\n",
      "       10    0.000    0.000    0.002    0.000 frame.py:1999(_getitem_column)\n",
      "       23    0.000    0.000    0.000    0.000 common.py:1710(is_datetimetz)\n",
      "        1    0.000    0.000    0.000    0.000 parsers.py:653(_get_options_with_defaults)\n",
      "       10    0.000    0.000    0.000    0.000 base.py:1247(__getitem__)\n",
      "       24    0.000    0.000    0.000    0.000 proxydict.py:42(__setitem__)\n",
      "       12    0.000    0.000    0.000    0.000 {method 'min' of 'numpy.ndarray' objects}\n",
      "       47    0.000    0.000    0.000    0.000 leaf.py:147(<lambda>)\n",
      "      5/2    0.000    0.000    0.000    0.000 utils.py:140(check_file_access)\n",
      "       17    0.000    0.000    0.000    0.000 node.py:157(_g_getparent)\n",
      "        6    0.000    0.000    0.000    0.000 weakref.py:162(iterkeys)\n",
      "       26    0.000    0.000    0.000    0.000 utils.py:49(is_idx)\n",
      "        1    0.000    0.000    0.002    0.002 parsers.py:603(__init__)\n",
      "       10    0.000    0.000    0.000    0.000 generic.py:1359(_set_as_cached)\n",
      "        1    0.000    0.000    0.000    0.000 parsers.py:883(__init__)\n",
      "        5    0.000    0.000    0.000    0.000 filters.py:245(_pack)\n",
      "       45    0.000    0.000    0.000    0.000 {method 'groups' of '_sre.SRE_Match' objects}\n",
      "       50    0.000    0.000    0.000    0.000 {method 'getvalue' of '_io.StringIO' objects}\n",
      "        1    0.000    0.000    0.000    0.000 {pandas.lib.array_equivalent_object}\n",
      "       10    0.000    0.000    0.000    0.000 internals.py:3914(get_values)\n",
      "        6    0.000    0.000    0.000    0.000 filters.py:275(__init__)\n",
      "        3    0.000    0.000    0.000    0.000 internals.py:2619(shape)\n",
      "       99    0.000    0.000    0.000    0.000 {method 'group' of '_sre.SRE_Match' objects}\n",
      "        1    0.000    0.000    0.000    0.000 arrayprint.py:635(__init__)\n",
      "       25    0.000    0.000    0.000    0.000 threading.py:958(name)\n",
      "       50    0.000    0.000    0.000    0.000 {method 'release' of 'thread.lock' objects}\n",
      "       14    0.000    0.000    0.000    0.000 {method '_g_new' of 'tables.hdf5extension.Leaf' objects}\n",
      "       18    0.000    0.000    0.000    0.000 base.py:3381(_ensure_index)\n",
      "        5    0.000    0.000    0.001    0.000 file.py:2024(__contains__)\n",
      "       10    0.000    0.000    0.000    0.000 generic.py:2658(__getattr__)\n",
      "        1    0.000    0.000    0.006    0.006 frame.py:210(__init__)\n",
      "       50    0.000    0.000    0.000    0.000 hmac.py:30(__init__)\n",
      "        1    0.000    0.000    0.000    0.000 base.py:1507(equals)\n",
      "        1    0.000    0.000    0.000    0.000 parsers.py:683(_clean_options)\n",
      "       10    0.000    0.000    0.000    0.000 common.py:986(_possibly_castable)\n",
      "      122    0.000    0.000    0.000    0.000 {method 'pop' of 'dict' objects}\n",
      "        2    0.000    0.000    0.000    0.000 internals.py:276(ftype)\n",
      "        1    0.000    0.000    0.000    0.000 internals.py:3004(_consolidate_check)\n",
      "       30    0.000    0.000    0.000    0.000 {numpy.core.umath.seterrobj}\n",
      "       52    0.000    0.000    0.000    0.000 {method 'copy' of 'dict' objects}\n",
      "       45    0.000    0.000    0.000    0.000 {divmod}\n",
      "        1    0.000    0.000    0.002    0.002 internals.py:3996(create_block_manager_from_arrays)\n",
      "        4    0.000    0.000    0.002    0.001 file.py:917(create_group)\n",
      "       10    0.000    0.000    0.000    0.000 internals.py:183(make_block_same_class)\n",
      "       23    0.000    0.000    0.000    0.000 common.py:1575(is_datetime64tz_dtype)\n",
      "        3    0.000    0.000    0.001    0.000 carray.py:223(_g_create_common)\n",
      "       10    0.000    0.000    0.000    0.000 internals.py:4171(_asarray_compat)\n",
      "       10    0.000    0.000    0.000    0.000 series.py:306(name)\n",
      "        6    0.000    0.000    0.001    0.000 arrayprint.py:340(array2string)\n",
      "       27    0.000    0.000    0.000    0.000 inspect.py:142(isfunction)\n",
      "       41    0.000    0.000    0.000    0.000 copy_reg.py:92(__newobj__)\n",
      "        2    0.000    0.000    0.000    0.000 urlparse.py:137(urlparse)\n",
      "       48    0.000    0.000    0.000    0.000 file.py:2128(_check_open)\n",
      "        1    0.000    0.000    0.000    0.000 {eval}\n",
      "       27    0.000    0.000    0.000    0.000 inspect.py:209(iscode)\n",
      "       16    0.000    0.000    0.000    0.000 file.py:2167(is_undo_enabled)\n",
      "       21    0.000    0.000    0.000    0.000 table.py:616(<lambda>)\n",
      "       30    0.000    0.000    0.000    0.000 {method 'indices' of 'slice' objects}\n",
      "        4    0.000    0.000    0.000    0.000 dtypes.py:122(construct_from_string)\n",
      "       10    0.000    0.000    0.000    0.000 common.py:94(_isnull_new)\n",
      "       10    0.000    0.000    0.000    0.000 common.py:1717(is_extension_type)\n",
      "       15    0.000    0.000    0.000    0.000 numeric.py:2967(__enter__)\n",
      "        4    0.000    0.000    0.000    0.000 numeric.py:676(<genexpr>)\n",
      "        5    0.000    0.000    0.000    0.000 group.py:271(__del__)\n",
      "        2    0.000    0.000    0.000    0.000 base.py:309(_simple_new)\n",
      "       10    0.000    0.000    0.000    0.000 internals.py:3911(internal_values)\n",
      "       61    0.000    0.000    0.000    0.000 {method 'rstrip' of 'str' objects}\n",
      "       53    0.000    0.000    0.000    0.000 {method '__contains__' of 'frozenset' objects}\n",
      "        5    0.000    0.000    0.002    0.000 earray.py:137(__init__)\n",
      "        1    0.000    0.000    0.000    0.000 getopt.py:51(getopt)\n",
      "        3    0.000    0.000    0.001    0.000 file.py:1256(create_earray)\n",
      "       30    0.000    0.000    0.000    0.000 proxydict.py:25(__init__)\n",
      "       15    0.000    0.000    0.000    0.000 numeric.py:2972(__exit__)\n",
      "       16    0.000    0.000    0.000    0.000 common.py:1731(is_categorical)\n",
      "        1    0.000    0.000    0.000    0.000 {tables.utilsextension.read_f_attr}\n",
      "        2    0.000    0.000    0.000    0.000 UserDict.py:4(__init__)\n",
      "       12    0.000    0.000    0.000    0.000 {method 'max' of 'numpy.ndarray' objects}\n",
      "        9    0.000    0.000    0.000    0.000 utils.py:393(__init__)\n",
      "        1    0.000    0.000    0.006    0.006 parsers.py:810(read)\n",
      "       25    0.000    0.000    0.000    0.000 process.py:59(current_process)\n",
      "        2    0.000    0.000    0.000    0.000 range.py:42(__new__)\n",
      "       16    0.000    0.000    0.000    0.000 {method 'view' of 'numpy.ndarray' objects}\n",
      "       20    0.000    0.000    0.000    0.000 common.py:1846(_apply_if_callable)\n",
      "        1    0.000    0.000    0.002    0.002 parsers.py:797(_make_engine)\n",
      "       60    0.000    0.000    0.000    0.000 {numpy.core.umath.geterrobj}\n",
      "       20    0.000    0.000    0.000    0.000 common.py:1705(is_sparse)\n",
      "        2    0.000    0.000    0.000    0.000 common.py:1226(_default_index)\n",
      "        1    0.000    0.000    0.000    0.000 common.py:290(get_filepath_or_buffer)\n",
      "        6    0.000    0.000    0.000    0.000 base.py:440(values)\n",
      "       12    0.000    0.000    0.000    0.000 _methods.py:28(_amin)\n",
      "       23    0.000    0.000    0.000    0.000 file.py:447(drop_from_cache)\n",
      "        3    0.000    0.000    0.000    0.000 arrayprint.py:529(__init__)\n",
      "        9    0.000    0.000    0.008    0.001 leaf.py:721(flush)\n",
      "       10    0.000    0.000    0.000    0.000 internals.py:301(iget)\n",
      "        4    0.000    0.000    0.000    0.000 table.py:115(_index_pathname_of)\n",
      "        3    0.000    0.000    0.000    0.000 group.py:288(_g_get_child_group_class)\n",
      "       10    0.000    0.000    0.000    0.000 internals.py:3884(dtype)\n",
      "       15    0.000    0.000    0.000    0.000 numeric.py:2963(__init__)\n",
      "       20    0.000    0.000    0.000    0.000 atom.py:604(<lambda>)\n",
      "       25    0.000    0.000    0.000    0.000 process.py:161(name)\n",
      "        2    0.000    0.000    0.000    0.000 parsers.py:1016(_maybe_make_multi_index_columns)\n",
      "        1    0.000    0.000    0.000    0.000 parsers.py:860(_validate_parse_dates_arg)\n",
      "       20    0.000    0.000    0.000    0.000 leaf.py:358(<genexpr>)\n",
      "        5    0.000    0.000    0.000    0.000 description.py:608(get_cols_in_order)\n",
      "        4    0.000    0.000    1.380    0.345 table.py:2971(copy)\n",
      "        9    0.000    0.000    0.000    0.000 table.py:1001(_get_container)\n",
      "        2    0.000    0.000    0.000    0.000 array.py:233(_g_open)\n",
      "        6    0.000    0.000    0.001    0.000 numeric.py:1835(array_str)\n",
      "        2    0.000    0.000    0.000    0.000 base.py:445(get_values)\n",
      "       14    0.000    0.000    0.000    0.000 {math.log10}\n",
      "        2    0.000    0.000    0.000    0.000 range.py:117(_simple_new)\n",
      "        5    0.000    0.000    0.000    0.000 {method '_flush_buffered_rows' of 'tables.tableextension.Row' objects}\n",
      "       15    0.000    0.000    0.000    0.000 _methods.py:31(_sum)\n",
      "       10    0.000    0.000    0.000    0.000 series.py:371(get_values)\n",
      "        3    0.000    0.000    0.000    0.000 common.py:1511(_get_dtype_type)\n",
      "        3    0.000    0.000    0.000    0.000 getopt.py:202(short_has_arg)\n",
      "        1    0.000    0.000    0.000    0.000 common.py:186(_is_url)\n",
      "       11    0.000    0.000    0.000    0.000 frame.py:321(<genexpr>)\n",
      "       50    0.000    0.000    0.000    0.000 py3compat.py:12(no_code)\n",
      "       12    0.000    0.000    0.000    0.000 arrayprint.py:450(_extendLine)\n",
      "       12    0.000    0.000    0.000    0.000 file.py:878(_get_or_create_path)\n",
      "        2    0.000    0.000    0.000    0.000 file.py:559(shutdown)\n",
      "        2    0.000    0.000    0.000    0.000 genericpath.py:34(isfile)\n",
      "        4    0.000    0.000    0.000    0.000 attributeset.py:591(_g_copy)\n",
      "        4    0.000    0.000    1.380    0.345 leaf.py:605(copy)\n",
      "        7    0.000    0.000    0.000    0.000 __init__.py:157(iteritems)\n",
      "       10    0.000    0.000    0.000    0.000 series.py:366(_values)\n",
      "       46    0.000    0.000    0.000    0.000 table.py:895(<genexpr>)\n",
      "        2    0.000    0.000    0.000    0.000 base.py:1143(_engine)\n",
      "        4    0.000    0.000    0.000    0.000 _weakrefset.py:26(__exit__)\n",
      "        7    0.000    0.000    0.000    0.000 leaf.py:30(csformula)\n",
      "       21    0.000    0.000    0.000    0.000 internals.py:2695(_get_items)\n",
      "       12    0.000    0.000    0.000    0.000 path.py:179(isvisiblename)\n",
      "       30    0.000    0.000    0.000    0.000 internals.py:3824(_block)\n",
      "        2    0.000    0.000    0.000    0.000 file.py:120(get_handlers_by_name)\n",
      "       41    0.000    0.000    0.000    0.000 description.py:612(join_paths)\n",
      "       10    0.000    0.000    0.000    0.000 base.py:2795(_maybe_cast_indexer)\n",
      "       10    0.000    0.000    0.000    0.000 series.py:313(dtype)\n",
      "        4    0.000    0.000    0.000    0.000 base.py:403(_reset_identity)\n",
      "        1    0.000    0.000    0.000    0.000 __init__.py:1131(setLevel)\n",
      "       10    0.000    0.000    0.000    0.000 series.py:292(_set_subtyp)\n",
      "       12    0.000    0.000    0.000    0.000 node.py:883(_g_check_name)\n",
      "       18    0.000    0.000    0.000    0.000 {method 'count' of 'str' objects}\n",
      "       12    0.000    0.000    0.000    0.000 FEParam.py:59(spe_i_to_v)\n",
      "       12    0.000    0.000    0.000    0.000 _methods.py:25(_amax)\n",
      "       10    0.000    0.000    0.000    0.000 common.py:1788(is_hashable)\n",
      "        2    0.000    0.000    0.000    0.000 <string>:8(__new__)\n",
      "       12    0.000    0.000    0.000    0.000 {method 'insert' of 'list' objects}\n",
      "       32    0.000    0.000    0.000    0.000 {pandas.lib.isscalar}\n",
      "        3    0.000    0.000    0.000    0.000 internals.py:2801(<genexpr>)\n",
      "       12    0.000    0.000    0.000    0.000 FEParam.py:62(spe_i_to_adc)\n",
      "        1    0.000    0.000    0.005    0.005 file.py:956(create_table)\n",
      "        1    0.000    0.000    0.000    0.000 internals.py:4122(_simple_blockify)\n",
      "        2    0.000    0.000    0.013    0.006 group.py:898(_g_close_descendents)\n",
      "        4    0.000    0.000    0.000    0.000 node.py:873(_g_maybe_remove)\n",
      "       12    0.000    0.000    0.000    0.000 file.py:2147(_check_writable)\n",
      "       10    0.000    0.000    0.000    0.000 internals.py:144(to_dense)\n",
      "        1    0.000    0.000    0.000    0.000 base.py:383(is_)\n",
      "        3    0.000    0.000    0.000    0.000 {print}\n",
      "        2    0.000    0.000    0.013    0.006 group.py:917(_f_close)\n",
      "        4    0.000    0.000    0.000    0.000 leaf.py:408(_process_range_read)\n",
      "        3    0.000    0.000    0.000    0.000 getopt.py:187(do_shorts)\n",
      "        6    0.000    0.000    0.000    0.000 base.py:409(__len__)\n",
      "       20    0.000    0.000    0.000    0.000 {method 'iteritems' of 'dict' objects}\n",
      "        1    0.000    0.000    0.000    0.000 common.py:1745(is_object_dtype)\n",
      "       12    0.000    0.000    0.000    0.000 file.py:2140(_iswritable)\n",
      "       16    0.000    0.000    0.000    0.000 internals.py:160(mgr_locs)\n",
      "        9    0.000    0.000    0.000    0.000 {method '_g_new' of 'tables.hdf5extension.Node' objects}\n",
      "        9    0.000    0.000    0.000    0.000 internals.py:2621(<genexpr>)\n",
      "        2    0.000    0.000    0.000    0.000 stat.py:49(S_ISREG)\n",
      "        4    0.000    0.000    0.000    0.000 leaf.py:174(filters)\n",
      "       12    0.000    0.000    0.000    0.000 carray.py:192(<genexpr>)\n",
      "        1    0.000    0.000    0.000    0.000 generic.py:813(keys)\n",
      "       30    0.000    0.000    0.000    0.000 {hash}\n",
      "        1    0.000    0.000    0.000    0.000 common.py:245(_expand_user)\n",
      "        2    0.000    0.000    0.000    0.000 file.py:112(remove)\n",
      "        5    0.000    0.000    0.000    0.000 utils.py:40(correct_byteorder)\n",
      "       13    0.000    0.000    0.000    0.000 {min}\n",
      "        2    0.000    0.000    0.000    0.000 internals.py:4177(_shape_compat)\n",
      "        2    0.000    0.000    0.000    0.000 base.py:1186(__iter__)\n",
      "        1    0.000    0.000    0.000    0.000 arrayprint.py:696(__init__)\n",
      "       12    0.000    0.000    0.000    0.000 internals.py:272(dtype)\n",
      "       25    0.000    0.000    0.000    0.000 posixpath.py:44(normcase)\n",
      "       10    0.000    0.000    0.000    0.000 common.py:73(isnull)\n",
      "        4    0.000    0.000    1.366    0.342 table.py:2876(_g_copy_rows)\n",
      "        2    0.000    0.000    0.077    0.039 file.py:2760(__exit__)\n",
      "        8    0.000    0.000    0.000    0.000 {method 'index' of 'list' objects}\n",
      "        2    0.000    0.000    0.000    0.000 base.py:1146(<lambda>)\n",
      "        4    0.000    0.000    0.000    0.000 _weakrefset.py:20(__enter__)\n",
      "        2    0.000    0.000    0.000    0.000 common.py:1696(is_bool_dtype)\n",
      "        8    0.000    0.000    0.000    0.000 {method 'add' of 'set' objects}\n",
      "        2    0.000    0.000    0.000    0.000 {method 'fill' of 'numpy.ndarray' objects}\n",
      "       15    0.000    0.000    0.000    0.000 leaf.py:188(_getmaindim)\n",
      "        1    0.000    0.000    0.000    0.000 parsers.py:1280(_set_noconvert_columns)\n",
      "        1    0.000    0.000    0.000    0.000 generic.py:381(_info_axis)\n",
      "       26    0.000    0.000    0.000    0.000 {operator.index}\n",
      "        9    0.000    0.000    0.000    0.000 file.py:177(_checkfilters)\n",
      "       12    0.000    0.000    0.000    0.000 {method 'remove' of 'list' objects}\n",
      "       20    0.000    0.000    0.000    0.000 {callable}\n",
      "        4    0.000    0.000    0.000    0.000 node.py:180(_g_gettitle)\n",
      "        9    0.000    0.000    0.000    0.000 node.py:293(__del__)\n",
      "        7    0.000    0.000    0.000    0.000 leaf.py:40(limit_es)\n",
      "        4    0.000    0.000    0.000    0.000 attributeset.py:265(_f_list)\n",
      "        1    0.000    0.000    0.000    0.000 {sum}\n",
      "        2    0.000    0.000    0.000    0.000 urlparse.py:168(urlsplit)\n",
      "        1    0.000    0.000    0.000    0.000 parsers.py:1024(_make_index)\n",
      "        1    0.000    0.000    0.000    0.000 base.py:938(is_unique)\n",
      "       41    0.000    0.000    0.000    0.000 {id}\n",
      "       11    0.000    0.000    0.000    0.000 atom.py:480(<lambda>)\n",
      "        5    0.000    0.000    0.000    0.000 internals.py:4140(<lambda>)\n",
      "        1    0.000    0.000    0.000    0.000 arrayprint.py:685(__init__)\n",
      "        1    0.000    0.000    0.000    0.000 common.py:204(_is_s3_url)\n",
      "        4    0.000    0.000    0.000    0.000 table.py:627(_v_iobuf)\n",
      "        4    0.000    0.000    0.000    0.000 table.py:109(_index_name_of)\n",
      "        1    0.000    0.000    0.000    0.000 {tables.utilsextension.which_lib_version}\n",
      "        1    0.000    0.000    0.000    0.000 table.py:2240(_save_buffered_rows)\n",
      "        8    0.000    0.000    0.000    0.000 table.py:870(<genexpr>)\n",
      "        9    0.000    0.000    0.000    0.000 {method 'itervalues' of 'dict' objects}\n",
      "        1    0.000    0.000    0.000    0.000 {sorted}\n",
      "        2    0.000    0.000    0.000    0.000 genericpath.py:23(exists)\n",
      "       20    0.000    0.000    0.000    0.000 attributeset.py:651(_g_close)\n",
      "        1    0.000    0.000    0.000    0.000 parsers.py:2293(_process_date_conversion)\n",
      "       20    0.000    0.000    0.000    0.000 {method '_g_new' of 'tables.hdf5extension.AttributeSet' objects}\n",
      "        2    0.000    0.000    0.000    0.000 internals.py:264(shape)\n",
      "        4    0.000    0.000    0.000    0.000 UserDict.py:34(__len__)\n",
      "        8    0.000    0.000    0.000    0.000 {method 'remove' of 'set' objects}\n",
      "        8    0.000    0.000    0.000    0.000 table.py:612(<lambda>)\n",
      "        5    0.000    0.000    0.000    0.000 {method 'item' of 'numpy.ndarray' objects}\n",
      "       20    0.000    0.000    0.000    0.000 {pandas.lib.is_float}\n",
      "        1    0.000    0.000    0.000    0.000 arrayprint.py:713(__init__)\n",
      "        1    0.000    0.000    0.000    0.000 parsers.py:1182(_do_date_conversions)\n",
      "        3    0.000    0.000    0.000    0.000 group.py:180(_g_getfilters)\n",
      "        3    0.000    0.000    0.000    0.000 arrayprint.py:657(__init__)\n",
      "       10    0.000    0.000    0.000    0.000 numeric.py:126(is_all_dates)\n",
      "        5    0.000    0.000    0.000    0.000 {method '_open_append' of 'tables.tableextension.Table' objects}\n",
      "        1    0.000    0.000    0.000    0.000 range.py:150(_data)\n",
      "       11    0.000    0.000    0.000    0.000 parsers.py:1384(<genexpr>)\n",
      "        4    0.000    0.000    0.000    0.000 weakref.py:68(_commit_removals)\n",
      "       14    0.000    0.000    0.000    0.000 node.py:463(_g_post_init_hook)\n",
      "        1    0.000    0.000    0.000    0.000 __init__.py:177(_checkLevel)\n",
      "        4    0.000    0.000    0.000    0.000 _weakrefset.py:16(__init__)\n",
      "        2    0.000    0.000    0.000    0.000 {pandas.algos.ensure_object}\n",
      "        1    0.000    0.000    0.000    0.000 {_functools.reduce}\n",
      "        1    0.000    0.000    0.000    0.000 parsers.py:2376(_clean_na_values)\n",
      "        2    0.000    0.000    0.000    0.000 {all}\n",
      "        1    0.000    0.000    0.000    0.000 parsers.py:941(_has_complex_date_col)\n",
      "        1    0.000    0.000    0.000    0.000 posixpath.py:251(expanduser)\n",
      "        1    0.000    0.000    0.000    0.000 common.py:263(_validate_header_arg)\n",
      "       10    0.000    0.000    0.000    0.000 internals.py:129(internal_values)\n",
      "        1    0.000    0.000    0.000    0.000 internals.py:3276(_consolidate_inplace)\n",
      "        1    0.000    0.000    0.000    0.000 parsers.py:843(_validate_usecols_arg)\n",
      "        1    0.000    0.000    0.000    0.000 FEParam.py:89(W_LPF_daq)\n",
      "        1    0.000    0.000    0.000    0.000 parsers.py:2255(_make_date_converter)\n",
      "        2    0.000    0.000    0.000    0.000 stat.py:24(S_IFMT)\n",
      "        1    0.000    0.000    0.000    0.000 FEParam.py:71(f_HPF)\n",
      "        1    0.000    0.000    0.000    0.000 parsers.py:829(_create_index)\n",
      "        1    0.000    0.000    0.000    0.000 {method 'items' of 'dict' objects}\n",
      "        1    0.000    0.000    0.000    0.000 FEParam.py:80(W_HPF_daq)\n",
      "        2    0.000    0.000    0.000    0.000 {method 'values' of 'dict' objects}\n",
      "        2    0.000    0.000    0.000    0.000 utils.py:61(set_vml_num_threads)\n",
      "        4    0.000    0.000    0.000    0.000 range.py:58(_ensure_int)\n",
      "        1    0.000    0.000    0.000    0.000 common.py:271(_stringify_path)\n",
      "        1    0.000    0.000    0.000    0.000 FEParam.py:68(decoupling_resitor)\n",
      "        1    0.000    0.000    0.000    0.000 FEParam.py:49(pmt_gain)\n",
      "        1    0.000    0.000    0.000    0.000 internals.py:2996(is_consolidated)\n",
      "        1    0.000    0.000    0.000    0.000 FEParam.py:52(sampling_time)\n",
      "        1    0.000    0.000    0.000    0.000 <string>:1(<module>)\n",
      "        1    0.000    0.000    0.000    0.000 arrayprint.py:734(__init__)\n",
      "        1    0.000    0.000    0.000    0.000 {pandas.lib.is_bool}\n",
      "        1    0.000    0.000    0.000    0.000 FEParam.py:65(decoupling_capacitor)\n",
      "        2    0.000    0.000    0.000    0.000 internals.py:2623(ndim)\n",
      "        1    0.000    0.000    0.000    0.000 {method 'disable' of '_lsprof.Profiler' objects}\n",
      "        2    0.000    0.000    0.000    0.000 range.py:139(_validate_dtype)\n",
      "        1    0.000    0.000    0.000    0.000 FEParam.py:55(sampling_DAQ)\n",
      "        4    0.000    0.000    0.000    0.000 {method 'iterkeys' of 'dict' objects}\n",
      "        1    0.000    0.000    0.000    0.000 FEParam.py:74(f_LPF)\n",
      "        2    0.000    0.000    0.000    0.000 {pandas.lib.is_integer}\n",
      "        1    0.000    0.000    0.000    0.000 FEParam.py:86(W_LPF_fine)\n",
      "        1    0.000    0.000    0.000    0.000 FEParam.py:77(W_HPF_fine)\n",
      "        2    0.000    0.000    0.000    0.000 file.py:2755(__enter__)\n",
      "        2    0.000    0.000    0.000    0.000 {method '_get_file_id' of 'tables.hdf5extension.File' objects}\n",
      "        2    0.000    0.000    0.000    0.000 {iter}\n",
      "        3    0.000    0.000    0.000    0.000 parsers.py:839(_is_index_col)\n",
      "\n",
      "\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Buffer dtype mismatch, expected 'int32_t' but got 'double'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-27-005d99e88e6b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mcProfile\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"DIOMIRA(['DIOMIRA','-i','-d','INFO','-c','../../Config/DIOMIRA_NA_ZLIB_test2.csv'])\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msort\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'time'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/local/Cellar/python/2.7.11/Frameworks/Python.framework/Versions/2.7/lib/python2.7/cProfile.pyc\u001b[0m in \u001b[0;36mrun\u001b[0;34m(statement, filename, sort)\u001b[0m\n\u001b[1;32m     27\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m             \u001b[0mprof\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprof\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstatement\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     30\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mSystemExit\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m             \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/Cellar/python/2.7.11/Frameworks/Python.framework/Versions/2.7/lib/python2.7/cProfile.pyc\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, cmd)\u001b[0m\n\u001b[1;32m    133\u001b[0m         \u001b[0;32mimport\u001b[0m \u001b[0m__main__\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    134\u001b[0m         \u001b[0mdict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m__main__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__dict__\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 135\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrunctx\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcmd\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    136\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    137\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mrunctx\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcmd\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mglobals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlocals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/Cellar/python/2.7.11/Frameworks/Python.framework/Versions/2.7/lib/python2.7/cProfile.pyc\u001b[0m in \u001b[0;36mrunctx\u001b[0;34m(self, cmd, globals, locals)\u001b[0m\n\u001b[1;32m    138\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    139\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 140\u001b[0;31m             \u001b[0;32mexec\u001b[0m \u001b[0mcmd\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mglobals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlocals\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    141\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    142\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdisable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<string>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m<ipython-input-26-1b77e47d2505>\u001b[0m in \u001b[0;36mDIOMIRA\u001b[0;34m(argv)\u001b[0m\n\u001b[1;32m    212\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    213\u001b[0m                 \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"--> rebin_signal: i ={}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 214\u001b[0;31m                 \u001b[0mtruePMT\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrebin_signal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mpmtrd_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mFP\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime_DAQ\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    215\u001b[0m                 \u001b[0mtruePMT\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    216\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m_cython_magic_b3792d1d4fc96b0de24710bf906a8a85.pyx\u001b[0m in \u001b[0;36m_cython_magic_b3792d1d4fc96b0de24710bf906a8a85.rebin_signal (/Users/jjgomezcadenas/Documents/Development/IPYTHON/cython/_cython_magic_b3792d1d4fc96b0de24710bf906a8a85.c:4077)\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m_cython_magic_b3792d1d4fc96b0de24710bf906a8a85.pyx\u001b[0m in \u001b[0;36m_cython_magic_b3792d1d4fc96b0de24710bf906a8a85.rebin_pmt_array (/Users/jjgomezcadenas/Documents/Development/IPYTHON/cython/_cython_magic_b3792d1d4fc96b0de24710bf906a8a85.c:1654)\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Buffer dtype mismatch, expected 'int32_t' but got 'double'"
     ]
    }
   ],
   "source": [
    "cProfile.run(\"DIOMIRA(['DIOMIRA','-i','-d','INFO','-c','../../Config/DIOMIRA_NA_ZLIB_test2.csv'])\", sort='time')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%cython\n",
    "import numpy as np\n",
    "cimport numpy as np\n",
    "from cython cimport boundscheck, wraparound\n",
    "def rebin_pmt_array(np.ndarray[np.float64_t, ndim=1] a,int stride):\n",
    "    \"\"\"\n",
    "    rebins pmt array a according to stride\n",
    "    there is a rebin_array in util which uses\n",
    "    lenb = (len(a))/int(stride)\n",
    "    this version uses (lean(a)+1) to correct from the fact that the\n",
    "    MCRD is 599999 channels (should be 600000)\n",
    "    \"\"\"\n",
    "    \n",
    "    print(\"*cyhon version*\")\n",
    "    cdef:\n",
    "        int lenb, i, j,k\n",
    "        double part_sum\n",
    "      \n",
    "    lenb = (a.shape[0]+1)/stride\n",
    "    cdef np.ndarray[np.float64_t, ndim=1] b = np.zeros(lenb) \n",
    "    \n",
    "    j=0\n",
    "    with boundscheck(False), wraparound(False):\n",
    "        for i in range(lenb):\n",
    "            part_sum = 0.\n",
    "            for k in range(j, j + stride): \n",
    "                part_sum += a[k] \n",
    "                b[i] = part_sum\n",
    "            j+= stride\n",
    "    \n",
    "    return b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "rebin_pmt_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cProfile.run(\"DIOMIRA(['DIOMIRA','-i','-d','INFO','-c','../../Config/DIOMIRA_NA_ZLIB_test2.csv'])\", sort='time')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "h5f =tables.open_file('/Users/jjgomezcadenas/Documents/Development/NEXT/data/Waveforms/25ns/WF_Na_ZLIB_test100_RWF.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pmtrwf = h5f.root.RD.pmtrwf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Python version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "def rebin_pmt_array(a,stride):\n",
    "    \"\"\"\n",
    "    rebins pmt array a according to stride\n",
    "    there is a rebin_array in util which uses\n",
    "    lenb = (len(a))/int(stride)\n",
    "    this version uses (lean(a)+1) to correct from the fact that the\n",
    "    MCRD is 599999 channels (should be 600000)\n",
    "    \"\"\"\n",
    "    #t1 = time()\n",
    "    #print(\"rebin_pmt_array\")\n",
    "    lenb = (len(a)+1)/int(stride)\n",
    "    b = np.zeros(lenb)\n",
    "    j=0\n",
    "    for i in range(lenb):\n",
    "        b[i] = np.sum(a[j:j+stride])\n",
    "        j+= stride\n",
    "    #t2 = time()\n",
    "    #print('time = {}'.format(t2-t1))\n",
    "    return b\n",
    "\n",
    "def rebin_signal(event_number,pmtrd_, stride):\n",
    "    \"\"\"\n",
    "    rebins the MCRD signal to produce TWF (pes, bins 25 ns)\n",
    "    \"\"\"\n",
    "    t1 = time()\n",
    "    rdata = []\n",
    "\n",
    "    for j in range(pmtrd_.shape[1]):\n",
    "        pmt = pmtrd_[event_number, j] #waveform for event event_number, PMT j\n",
    "        #print(\"pmt = {}: Call rebin_pmt_array\".format(j))\n",
    "        t2 = time()\n",
    "        twf = rebin_pmt_array(pmt, stride)\n",
    "        #print('time = {}'.format(t2-t1))\n",
    "        \n",
    "        rdata.append(twf)\n",
    "    return np.array(rdata)\n",
    "\n",
    "def rebin_signals(pmtrd, stride=40, list_of_events=[0]):\n",
    "    \"\"\"\n",
    "    rebin the signals in a list of events\n",
    "    \"\"\"\n",
    "    t1 = time()\n",
    "    for event in list_of_events:\n",
    "        print(\"event = {}. Call rebin signal\".format(event))\n",
    "        rebin_signal(event,pmtrd, stride)\n",
    "        t2 = time()\n",
    "        print('time = {}'.format(t2-t1))\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "rebin_signals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%time rebin_signals(pmtrwf, stride=40, list_of_events=range(100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cython version (just compile python)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%cython\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import FEParam as FP\n",
    "import tables\n",
    "\n",
    "def rebin_pmt_array(a,stride):\n",
    "    \"\"\"\n",
    "    rebins pmt array a according to stride\n",
    "    there is a rebin_array in util which uses\n",
    "    lenb = (len(a))/int(stride)\n",
    "    this version uses (lean(a)+1) to correct from the fact that the\n",
    "    MCRD is 599999 channels (should be 600000)\n",
    "    \"\"\"\n",
    "    \n",
    "    lenb = (len(a)+1)/int(stride)\n",
    "    b = np.zeros(lenb)\n",
    "    j=0\n",
    "    for i in range(lenb):\n",
    "        b[i] = np.sum(a[j:j+stride])\n",
    "        j+= stride\n",
    "    return b\n",
    "\n",
    "def rebin_signal(event_number,pmtrd_, stride):\n",
    "    \"\"\"\n",
    "    rebins the MCRD signal to produce TWF (pes, bins 25 ns)\n",
    "    \"\"\"\n",
    "    \n",
    "    rdata = []\n",
    "\n",
    "    for j in range(pmtrd_.shape[1]):\n",
    "        pmt = pmtrd_[event_number, j] #waveform for event event_number, PMT j\n",
    "        twf = rebin_pmt_array(pmt, stride)\n",
    "        \n",
    "        rdata.append(twf)\n",
    "    return np.array(rdata)\n",
    "\n",
    "def rebin_signals(pmtrd, stride=40, list_of_events=[0]):\n",
    "    \"\"\"\n",
    "    rebin the signals in a list of events\n",
    "    \"\"\"\n",
    "    for event in list_of_events:\n",
    "        rebin_signal(event,pmtrd, stride)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "rebin_signals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def rebin_signal(event_number,pmtrd_, stride):\n",
    "    \"\"\"\n",
    "    rebins the MCRD signal to produce TWF (pes, bins 25 ns)\n",
    "    \"\"\"\n",
    "    t1 = time()\n",
    "    rdata = []\n",
    "\n",
    "    for j in range(pmtrd_.shape[1]):\n",
    "        pmt = pmtrd_[event_number, j] #waveform for event event_number, PMT j\n",
    "        #print(\"pmt = {}: Call rebin_pmt_array\".format(j))\n",
    "        t2 = time()\n",
    "        twf = rebin_pmt_array(pmt, stride)\n",
    "        #print('time = {}'.format(t2-t1))\n",
    "        \n",
    "        rdata.append(twf)\n",
    "    return np.array(rdata)\n",
    "\n",
    "def rebin_signals(pmtrd, stride=40, list_of_events=[0]):\n",
    "    \"\"\"\n",
    "    rebin the signals in a list of events\n",
    "    \"\"\"\n",
    "    t1 = time()\n",
    "    for event in list_of_events:\n",
    "        print(\"event = {}. Call rebin signal\".format(event))\n",
    "        rebin_signal(event,pmtrd, stride)\n",
    "        t2 = time()\n",
    "        print('time = {}'.format(t2-t1))\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "rebin_signals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "rebin_signal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "rebin_pmt_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "3000.*25./1000."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%time rebin_signals(pmtrwf, stride=40, list_of_events=range(100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cython version (supposedly optimized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%cython\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import FEParam as FP\n",
    "import tables\n",
    "from time import time\n",
    "\n",
    "def rebin_pmt_array(float [:] a,int stride):\n",
    "    \"\"\"\n",
    "    rebins pmt array a according to stride\n",
    "    there is a rebin_array in util which uses\n",
    "    lenb = (len(a))/int(stride)\n",
    "    this version uses (lean(a)+1) to correct from the fact that the\n",
    "    MCRD is 599999 channels (should be 600000)\n",
    "    \"\"\"\n",
    "    cdef int lenb\n",
    "    lenb = (len(a)+1)/stride\n",
    "    b = np.zeros(lenb, dtype = np.float)\n",
    "    cdef int j=0\n",
    "    cdef int i\n",
    "    for i in range(lenb):\n",
    "        b[i] = np.sum(a[j:j+stride])\n",
    "        j+= stride\n",
    "    return b\n",
    "\n",
    "# def rebin_signal(int event_number, pmtrd_, int stride):\n",
    "#     \"\"\"\n",
    "#     rebins the MCRD signal to produce TWF (pes, bins 25 ns)\n",
    "#     \"\"\"\n",
    "    \n",
    "#     #rdata = np.zeros(pmtrd_.shape[1], dtype = np.object)\n",
    "#     rdata = []\n",
    "#     cdef int j\n",
    "#     for j in range(pmtrd_.shape[1]):\n",
    "#         pmt = pmtrd_[event_number, j] #waveform for event event_number, PMT j\n",
    "#         twf = rebin_pmt_array(pmt, stride)\n",
    "        \n",
    "#         rdata.append(twf)\n",
    "#     return np.array(rdata)\n",
    "\n",
    "# def rebin_signals(pmtrd, int stride, list_of_events):\n",
    "#     \"\"\"\n",
    "#     rebin the signals in a list of events\n",
    "#     \"\"\"\n",
    "#     cdef int event\n",
    "#     for event in list_of_events:\n",
    "#         rebin_signal(event,pmtrd, stride)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "rebin_pmt_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%timeit rebin_signals(pmtrwf, stride=40, list_of_events=range(100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cython does not improve over python code in this case!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "h5f.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
