{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import logging\n",
    "\n",
    "# ---------------------------------------------------------------------------------------------------------\n",
    "# USER INPUTS\n",
    "# ---------------------------------------------------------------------------------------------------------\n",
    "\n",
    "# Directory and run names\n",
    "datdir = \"/Users/alej/Desktop/Valencia/IC/Notebooks\"                          # the base data directory\n",
    "dname = \"resp.h\"         # the data name\n",
    "rdir = \"/Users/alej/Desktop/Valencia/IC/Notebooks\"             # the run directory\n",
    "rname = \"reconstructionDNN_output\"\n",
    "\n",
    "# Net configuration parameters\n",
    "net_name = \"MNISTadv\"                    # name of the neural net described in nets/neuralnets.py\n",
    "train_init = True                          # if true, train from net with standard pre-training; if false, read in a previously trained net\n",
    "\n",
    "# Response map parameters\n",
    "nsipm = 8\n",
    "ngrid = 2\n",
    "\n",
    "# Parameters describing training intervals and number of events for training and validation\n",
    "ntrain_evts = 40000    # number of training evts per dataset\n",
    "nval_evts = 5000       # number of validation events\n",
    "num_epochs = 80        # total number of epochs to train\n",
    "epoch_blk_size = 1     # number of epochs to run per block (before reading new dataset); \n",
    "                       # set equal to num_epochs unless data to be read in multiple blocks\n",
    "dtblk_size = ntrain_evts      # number of signal and background events per training block\n",
    "batch_size = 250       # training batch size\n",
    "\n",
    "# Training optimizer parameters\n",
    "opt_lr = 1.0e-3       # optimizer learning rate\n",
    "opt_eps = 1.0e-7      # optimizer epsilon (for AdamOptimizer)\n",
    "opt_mom = 0.9          # optimizer momentum\n",
    "opt_decaybase = 0.1    # multiplicative factor for learning rate decay\n",
    "opt_ndecayepochs = 50  # decay interval: apply decay by a factor of opt_decaybase every opt_ndecayepochs epochs\n",
    "\n",
    "# Plotting and logging parameters\n",
    "log_to_file = True         # set to True to output log information to a file rather than the console\n",
    "logging_lvl = logging.INFO  # logging level: DEBUG, INFO, WARNING, ERROR, CRITICAL\n",
    "#plt_show = False       # show plots on-screen for dnnplot\n",
    "#plt_imgtype = \"png\"    # image type to which to save plots\n",
    "\n",
    "# END USER INPUTS\n",
    "# ------------------------------------------------------------------------------------------\n",
    "\n",
    "# Calculated parameters (based on user inputs)\n",
    "batches_per_epoch = int(dtblk_size/batch_size)\n",
    "num_epoch_blks = num_epochs / epoch_blk_size\n",
    "num_dt_blks = ntrain_evts / dtblk_size\n",
    "nsensors = nsipm * nsipm\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
