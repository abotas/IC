{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "pt_classifer takes SiPM response maps and for each map (time slice)  and uses a neural network to determine how many hits there were in the EL plane."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using Theano backend.\n",
      "/usr/local/lib/python2.7/site-packages/matplotlib/font_manager.py:273: UserWarning: Matplotlib is building the font cache using fc-list. This may take a moment.\n",
      "  warnings.warn('Matplotlib is building the font cache using fc-list. This may take a moment.')\n"
     ]
    }
   ],
   "source": [
    "from keras.models               import Sequential\n",
    "from keras.layers               import Dense, Activation, Dropout\n",
    "from keras.optimizers           import SGD, Adam, Nadam         \n",
    "from keras                      import callbacks\n",
    "from keras.layers.convolutional import Convolution2D, MaxPooling2D\n",
    "from keras.layers.core          import Flatten\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "import numpy as np\n",
    "import tables as tb\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# data filename should contain SiPM maps for 1,2, ..., max_hits\n",
    "data_filename = 'TMC_data.h' \n",
    "#data_filename = 'Full_TMC_data.h' \n",
    "max_hits = 3 # (up to 4)\n",
    "\n",
    "nsipm = 8\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "f = tb.open_file('TMC_data.h','r')\n",
    "h1_train = f.root.sim_1pt.xtrain\n",
    "h1_valid = f.root.sim_1pt.xvalid\n",
    "\n",
    "h2_train = f.root.sim_2pt.xtrain  \n",
    "h2_valid = f.root.sim_2pt.xvalid \n",
    "\n",
    "h3_train = f.root.sim_3pt.xtrain\n",
    "h3_valid = f.root.sim_3pt.xvalid\n",
    "    \n",
    "One_Hot_Encoding = True # set to true for one hot encoded labels\n",
    "def organize(hits):\n",
    "    # input organize your training data as a list of numpy arrays (or earrays)\n",
    "    # organize outputs your training matrix of SiPM maps and their one hot encoded labels\n",
    "    \n",
    "    length = sum([pt.shape[0] for pt in hits])\n",
    "    x = np.array(hits)\n",
    "    x = x.reshape((length,h1_train.shape[1]))\n",
    "    \n",
    "    y = np.array([np.ones(pt.shape[0],np.int) * i for pt,i in zip(hits,range(1,len(hits)+1))])\n",
    "    y = y.reshape((length))\n",
    "    \n",
    "    if One_Hot_Encoding:\n",
    "        yh = np.zeros((length,len(hits)),np.int)\n",
    "        i=0\n",
    "        for numhits in y:\n",
    "            yh[i,numhits-1] = 1\n",
    "            i+=1\n",
    "        return(x,yh)\n",
    "    \n",
    "    return x,y\n",
    "\n",
    "# important to note these are unshuffled, but they will be shuffled during training so it should be fine\n",
    "x_train,y_train = organize([h1_train,h2_train,h3_train])\n",
    "x_valid,y_valid = organize([h1_valid,h2_valid,h3_valid])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define some networks:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# construct a 5 layer network\n",
    "\n",
    "def cnn():\n",
    "    model = Sequential()\n",
    " \n",
    "    # **Worth taking into consideration that our image size is tiny (8x8), convolution may work much better for \n",
    "    # **with 1792 sipms\n",
    "    \n",
    "    # kernal size is 3x3, 32 filters\n",
    "    model.add(Convolution2D(32,3,3,border_mode='same',input_shape=(1, nsipm, nsipm)))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Convolution2D(32,3,3,border_mode='same', input_shape=(32, nsipm, nsipm)))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(output_dim=128))\n",
    "    model.add(Activation('relu'))      \n",
    "    model.add(Dense(output_dim=64))\n",
    "    model.add(Activation('relu'))  \n",
    "    model.add(Dense(max_hits))\n",
    "    model.add(Activation('sigmoid'))\n",
    "\n",
    "    # Nadam optimizer is a safe choice at least for deep networks. It is adam optimizer with Nesterov\n",
    "    # Momentum. Nesterov Momentum takes into account future expected future gradient gradient, unlike traditional Mom.\n",
    "    model.compile(loss='mse', optimizer=Nadam(lr=0.002, beta_1=0.9, beta_2=0.999, epsilon=1e-08, schedule_decay=0.004))\n",
    "    N_layers = 'cnn'\n",
    "    return model,N_layers\n",
    "    \n",
    "\n",
    "def lay5():\n",
    "    model = Sequential()\n",
    "    model.add(Dense(output_dim=2048, input_dim=nsipm*nsipm))\n",
    "    model.add(Activation(\"relu\"))\n",
    "    model.add(Dense(output_dim=1024))\n",
    "    model.add(Activation(\"relu\"))\n",
    "    model.add(Dense(output_dim=512))\n",
    "    model.add(Activation(\"relu\"))\n",
    "    model.add(Dense(output_dim=256))\n",
    "    model.add(Activation(\"relu\"))\n",
    "    model.add(Dropout(.25))    # **Note this is drop rate, not keep rate (like in tf)\n",
    "    model.add(Dense(output_dim=max_hits))\n",
    "    model.add(Activation(\"sigmoid\"))\n",
    "    \n",
    "    # Nadam optimizer is probabaly a safe choice at least for our deep networks. It is adam optimizer with Nesterov\n",
    "    # Momentum. Nesterov Momentum takes into account future expected future gradient gradient, unlike traditional Mom.\n",
    "    model.compile(loss='categorical_crossentropy', \n",
    "                  optimizer=Nadam(lr=0.002, beta_1=0.9, beta_2=0.999, epsilon=1e-08, schedule_decay=0.004))\n",
    "    model.summary()\n",
    "    N_layers = 'cnn'\n",
    "    return model,N_layers\n",
    "    \n",
    "# construct a 4 layer network\n",
    "def lay4():\n",
    "    model = Sequential()\n",
    "    model.add(Dense(output_dim=2048, input_dim=nsipm*nsipm))\n",
    "    model.add(Activation(\"relu\"))\n",
    "    model.add(Dense(output_dim=1024))\n",
    "    model.add(Activation(\"relu\"))\n",
    "    model.add(Dense(output_dim=512))\n",
    "    model.add(Activation(\"relu\"))\n",
    "    model.add(Dropout(.2))\n",
    "    model.add(Dense(output_dim=max_hits))\n",
    "    model.add(Activation(\"sigmoid\"))\n",
    "    model.compile(loss='categorical_crossentropy', \n",
    "                  optimizer=Nadam(lr=0.002, beta_1=0.9, beta_2=0.999, epsilon=1e-08, schedule_decay=0.004))\n",
    "    model.summary()\n",
    "    N_layers = 4\n",
    "    return model,N_layers\n",
    "    \n",
    "# etc .. \n",
    "def lay3():\n",
    "    model = Sequential()\n",
    "    model.add(Dense(output_dim=2048, input_dim=nsipm*nsipm))\n",
    "    model.add(Activation(\"relu\"))\n",
    "    model.add(Dense(output_dim=1024))\n",
    "    model.add(Activation(\"relu\"))\n",
    "    #model.add(Dropout(.15))\n",
    "    model.add(Dense(output_dim=max_hits))\n",
    "    model.add(Activation(\"sigmoid\"))\n",
    "    #model.compile(loss='mse', optimizer=SGD(lr=1.0, momentum=0.9, nesterov=True))\n",
    "    model.compile(loss='categorical_crossentropy', \n",
    "                  optimizer=Nadam(lr=0.002, beta_1=0.9, beta_2=0.999, epsilon=1e-08, schedule_decay=0.004))\n",
    "\n",
    "    model.summary()\n",
    "    N_layers = 3\n",
    "    return model,N_layers\n",
    "\n",
    "def lay2():\n",
    "    model = Sequential()\n",
    "    model.add(Dense(output_dim=2048, input_dim=nsipm*nsipm))\n",
    "    model.add(Activation(\"relu\"))\n",
    "    #model.add(Dropout(.25))\n",
    "    model.add(Dense(output_dim=max_hits))\n",
    "    model.add(Activation(\"softmax\"))\n",
    "    model.compile(loss ='categorical_crossentropy',  optimizer=SGD(lr=1.0, momentum=0.9, nesterov=True))\n",
    "    #model.compile(loss='mse', optimizer=Nadam(lr=0.002, beta_1=0.9, beta_2=0.999, epsilon=1e-08, schedule_decay=0.004))\n",
    "    model.summary()\n",
    "    N_layers = 2\n",
    "    return model,N_layers\n",
    "    \n",
    "def lay1():\n",
    "    model = Sequential()\n",
    "    model.add(Dense(output_dim=max_hits, input_dim=nsipm**2))\n",
    "    model.add(Activation(\"softmax\"))\n",
    "    model.compile(loss ='categorical_crossentropy',  optimizer=SGD(lr=1.0, momentum=0.9, nesterov=True))\n",
    "    model.summary()\n",
    "    N_layers = 1\n",
    "    return model,N_layers\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Call a network and begin training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 300000 samples, validate on 30000 samples\n",
      "Epoch 1/5\n",
      "122s - loss: 0.0360 - val_loss: 0.0195\n",
      "Epoch 2/5\n",
      "120s - loss: 0.0148 - val_loss: 0.0148\n",
      "Epoch 3/5\n",
      "127s - loss: 0.0124 - val_loss: 0.0115\n",
      "Epoch 4/5\n",
      "112s - loss: 0.0109 - val_loss: 0.0120\n",
      "Epoch 5/5\n",
      "110s - loss: 0.0098 - val_loss: 0.0105\n"
     ]
    }
   ],
   "source": [
    "# call desired network\n",
    "model,N_layers = cnn()\n",
    "\n",
    "# stop early and save best model\n",
    "ES = False\n",
    "Save_model = False\n",
    "if ES and Save_model:\n",
    "    callbacks = [\n",
    "        callbacks.EarlyStopping(monitor='val_loss', patience=3, mode='min'), # stop training if val_loss \n",
    "                                                                             # stops decreasing for 3 epochs\n",
    "        \n",
    "        callbacks.ModelCheckpoint(ES_filepath, monitor='val_loss', save_best_only=True, mode='min')] # save best model\n",
    "# stop early do not save    \n",
    "elif ES:\n",
    "    callbacks =[callbacks.EarlyStopping(monitor='val_loss', patience=3, mode='min')]\n",
    "\n",
    "# do not stop early, decide whether to save later *use this when comparing error of different numbers of layers\n",
    "else: callbacks =[]\n",
    "\n",
    "if N_layers == 'cnn':\n",
    "    hist = model.fit(x_train.reshape((y_train.shape[0],1,nsipm,nsipm)), y_train, nb_epoch=5, batch_size=100,  \n",
    "                 validation_data=(x_valid.reshape((y_valid.shape[0],1,nsipm,nsipm)),y_valid),\n",
    "                 verbose=2, callbacks=callbacks);  \n",
    "else:\n",
    "    hist = model.fit(x_train, y_train, nb_epoch=5, batch_size=100,  \n",
    "                 validation_data=(x_valid,y_valid),\n",
    "                 verbose=2, callbacks=callbacks); "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Determine accuracy:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 98.2033333333%\n",
      "correct: 29461.0\n",
      "total: 30000\n"
     ]
    }
   ],
   "source": [
    "# Get model's predictions, plot the error in a histogram\n",
    "if N_layers == 'cnn':\n",
    "    predictions = model.predict(x_valid.reshape((y_valid.shape[0],1,nsipm,nsipm)))\n",
    "else: \n",
    "    predictions = model.predict(x_valid)\n",
    "\n",
    "count = 0.0 \n",
    "for p,t in zip(predictions,y_valid):\n",
    "\n",
    "    if np.argmax(p) == np.argmax(t): \n",
    "        count +=1.0\n",
    "print('accuracy: ' + str(count/y_valid.shape[0]*100) + '%' )\n",
    "print('correct: ' + str(count))\n",
    "print('total: '   + str(y_valid.shape[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "This CNN has less than half the error of the 5layer DNN, after fewer epochs! It also takes less time/epoch to run than the 5 layer net!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
